<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Shapley Values/Shapley and Resnet" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Applying Shapley to the ResNet network | Explainable AI: Breaking Down the Black Box</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Applying Shapley to the ResNet network | Explainable AI: Breaking Down the Black Box"><meta data-rh="true" name="description" content="This section discusses the application of the `shap` package to the standard image-recognition architecture ResNet - both a standard version and a modified one we trained on brain tumor images."><meta data-rh="true" property="og:description" content="This section discusses the application of the `shap` package to the standard image-recognition architecture ResNet - both a standard version and a modified one we trained on brain tumor images."><link data-rh="true" rel="icon" href="/Explainable-Ai-Comps-2024/img/carleton-enhanced.ico"><link data-rh="true" rel="canonical" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet" hreflang="en"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/Explainable-Ai-Comps-2024/assets/css/styles.0e5b6101.css">
<script src="/Explainable-Ai-Comps-2024/assets/js/runtime~main.ef74a3ac.js" defer="defer"></script>
<script src="/Explainable-Ai-Comps-2024/assets/js/main.f4baef19.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Explainable-Ai-Comps-2024/"><div class="navbar__logo"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Explainable AI: Breaking Down the Black Box</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Explainable-Ai-Comps-2024/category/introduction">Writeup</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/Explainable-Ai-Comps-2024/About Us">About Us</a><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/introduction">Introduction</a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/methodology">Methodology</a><button aria-label="Expand sidebar category &#x27;Methodology&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/lime">LIME</a><button aria-label="Expand sidebar category &#x27;LIME&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/Explainable-Ai-Comps-2024/category/shapley-values">Shapley Values</a><button aria-label="Collapse sidebar category &#x27;Shapley Values&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC">Shapley and MOOC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet">Applying Shapley to the ResNet network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley&#x27;s Math">Shapley&#x27;s Math</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability">The EU&#x27;s Right to Explainability</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/anchors">Anchors</a><button aria-label="Expand sidebar category &#x27;Anchors&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study / Results</a><button aria-label="Expand sidebar category &#x27;User Study / Results&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/extensions">Extensions</a><button aria-label="Expand sidebar category &#x27;Extensions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Posters">Posters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Citations">Bibliography</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Explainable-Ai-Comps-2024/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Explainable-Ai-Comps-2024/category/shapley-values"><span itemprop="name">Shapley Values</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Applying Shapley to the ResNet network</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Applying Shapley to the ResNet network</h1>
<p>This section discusses the application of the <code>shap</code> package to the standard image-recognition architecture ResNet - both a standard version and a modified one we trained on brain tumor images.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="code">Code<a href="#code" class="hash-link" aria-label="Direct link to Code" title="Direct link to Code">​</a></h2>
<p>Despite being very different data from MOOC&#x27;s, Shapley could interpret its image data in much the same way. For the cats and dogs, for instance, our <code>Permutation</code> explainer was created as follows:</p>
<div class="language-Python language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> shap</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torchvision</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">models </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Import the model:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pretrained_weights </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> models</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ResNet18_Weights</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">IMAGENET1K_V1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">animal_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> models</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">resnet18</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">weights</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">pretrained_weights</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Create our explainer:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">masker_blur </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> shap</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">maskers</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Image</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;blur(128,128)&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> animal_X</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">explainer_blur </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> shap</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Explainer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">animal_torch_predict</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> masker_blur</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> output_names</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">class_names</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The masker is an important part of running Shapley on images. When we produce a coalition of pixels to remain in the image, what do we do with the rest of the picture? We can&#x27;t remove it, because the network always expects images of the same dimensions. Blacking it out is also problematic, because sometimes that will resemble something in the image. We opted to blur the rest of the image in this project.</p>
<p>Then, using <code>image_blur</code>, we explain a datapoint of our choice:</p>
<div class="language-Python language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">shap_values </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> explainer_blur</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    animal_picture</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    max_evals</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">eval_count</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">50</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> outputs</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">shap</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Explanation</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">argsort</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">flip</span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">top_guesses</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>The most important parameter here is <code>eval_count</code>. The higher the number, the more features it will split the image into. This is, perhaps, a little strange, because the image already has features: the red, green and blue values for each pixel. Shouldn&#x27;t we reuse those?</p>
<p>The problem is that Shapley&#x27;s runtime is proportional to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span>, where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> is the number of features. If we broke the image down into pixels, then, it&#x27;d take far too long to analyze. To this end, then, this Shapley implementation breaks up the image into a grid with regions that are small but are still larger than a pixel. An alternative method - used by <a href="/Explainable-Ai-Comps-2024/LIME/ResNet">LIME</a> - is to separate the image into a few &quot;superpixel&quot; clumps grouped by pixel color instead of location in image. We decided to use the grid, however, because it was better-integrated with the Shapley package and better showcased its strengths.</p>
<p>The other parameter here, <code>top_guesses</code>, here specifies how many of the model&#x27;s most confident answers you would like predictions for. Because the model outputs confidence for each of the thousand classes, not just the top, we can create the Shapley visualization for any class.
With the Shapley values in hand, we can now generate helpful visualizations.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="visual-explanations-of-animal-images">Visual Explanations of Animal Images<a href="#visual-explanations-of-animal-images" class="hash-link" aria-label="Direct link to Visual Explanations of Animal Images" title="Direct link to Visual Explanations of Animal Images">​</a></h2>
<p><img decoding="async" loading="lazy" alt="Abyssinian Cat" src="/Explainable-Ai-Comps-2024/assets/images/abyssinian-base-83eb3a51190a23d303cef28ec88ac7b2.jpg" title="An Orange Cat" width="378" height="300" class="img_ev3q"></p>
<p>The animal above is an Abyssinian cat. ResNet, our neural network, misidentified it as a snake - or perhaps a hat - before a cat. To be specific, its guesses in order were:</p>
<ul>
<li>Horned Viper: 0.21</li>
<li>Indian Cobra: 0.09</li>
<li>Sidewinder: 0.08</li>
<li>Cowboy Hat: 0.07</li>
<li>Egyptian cat: 0.06</li>
</ul>
<p>Followed by ResNet&#x27;s 995 other classes, which it deemed less likely than these five. While it&#x27;s not particularly confident that the subject of the image is a snake, it&#x27;s certainly held as the most likely outcome. So, we can use Shapley&#x27;s method to get a picture of why ResNet might have made this mistake.</p>
<p><img decoding="async" loading="lazy" alt="Cat" src="/Explainable-Ai-Comps-2024/assets/images/abyssinian-3-hd-262ce0fc5ad606f714296137bd80d462.png" title="Top guesses of the model and what pixels made it choose those classes" width="1417" height="372" class="img_ev3q"></p>
<p>The visualization produced by Shapley for each prediction is a heatmap. For each region - their number determined by <code>eval_count</code> - the overlay ranges from red (indicating that the area was instrumental in making the model identify the image as that class) to blue (indicating that it made the machine less likely to pick that class). For instance, on the snake predictions, the end of the tail, face, (and back, somewhat) are highlighted in red. One could imagine that the shape of the tail, especially, suggests snake to the model. On the other hand, the blanket and darker back of the cat are colored in blue, indicating that they were reasons to not call the cat a snake.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="visual-explantions-of-mri-scans">Visual Explantions of MRI scans<a href="#visual-explantions-of-mri-scans" class="hash-link" aria-label="Direct link to Visual Explantions of MRI scans" title="Direct link to Visual Explantions of MRI scans">​</a></h2>
<p>In addition to ResNet, we also ran a <a href="/Explainable-Ai-Comps-2024/Methodology/ResNet#tumors">model on a dataset of brain scans</a>. Because Shapley is model-agnostic, minimal changes were required to analyze tumor data as well.</p>
<p><img decoding="async" loading="lazy" alt="Meningioma-positive Brain Scan" src="/Explainable-Ai-Comps-2024/assets/images/meningioma-6921d06e96327d7aaaeb0e2a3c4da552.png" title="Top guesses of the model" width="1219" height="359" class="img_ev3q"></p>
<p>In this case - as with all of the other brain scan predictions we explained - Shapley&#x27;s picture is far less dynamic. Moreover, the actual tumor (white and slightly below the middle of the picture) is only very slightly highlighted, while an extraneous region at the top of the head is more strongly highlighted. This may point to it being a weaker model that is more reliant on guesswork; undeniably true. While this model got around 60-70% accuracy on our data with four classes, ResNet got 93.8% with a thousand classes. However, it does point to one interesting conclusion the model may have drawn: to look for tumors near the skull. If we were to tune the model, then, we could provide more examples of tumors that were not found at the edge of the brain.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/Shapley Values/Shapley and Resnet.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Shapley and MOOC</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley&#x27;s Math"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Shapley&#x27;s Math</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#code" class="table-of-contents__link toc-highlight">Code</a></li><li><a href="#visual-explanations-of-animal-images" class="table-of-contents__link toc-highlight">Visual Explanations of Animal Images</a></li><li><a href="#visual-explantions-of-mri-scans" class="table-of-contents__link toc-highlight">Visual Explantions of MRI scans</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Our Project</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Introduction">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Methodology">Methodology</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/Citations">Citations</a></li></ul></div><div class="col footer__col"><div class="footer__title">XAI Techniques</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/LIME">LIME</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Shapley-values">Shapley values</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Anchors">Anchors</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Repository<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Carleton College XAI Group | Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>