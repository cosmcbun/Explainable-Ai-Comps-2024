"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[3320],{5872:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>d});var n=i(7624),s=i(2172);const a={sidebar_position:4},o=void 0,r={id:"User Study/Limitations",title:"Limitations",description:"Resnet Survey Limitations",source:"@site/docs/User Study/Limitations.md",sourceDirName:"User Study",slug:"/User Study/Limitations",permalink:"/Explainable-Ai-Comps-2024/User Study/Limitations",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/User Study/Limitations.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/Explainable-Ai-Comps-2024/User Study/Introduction"},next:{title:"Quote Takeaways",permalink:"/Explainable-Ai-Comps-2024/User Study/Quote Takeaways"}},l={},d=[{value:"Resnet Survey Limitations",id:"resnet-survey-limitations",level:2},{value:"Data representations",id:"data-representations",level:3},{value:"Superpixels vs. pixel groups",id:"superpixels-vs-pixel-groups",level:3}];function p(e){const t={h2:"h2",h3:"h3",li:"li",p:"p",ul:"ul",...(0,s.M)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h2,{id:"resnet-survey-limitations",children:"Resnet Survey Limitations"}),"\n",(0,n.jsx)(t.h3,{id:"data-representations",children:"Data representations"}),"\n",(0,n.jsx)(t.p,{children:"Anchoring, LIME, and Shapley showed their explanations in different ways, which sometimes made it difficult to separate comments about the form of display from comments about the explanations themselves."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Anchoring displayed the unaltered anchor but blacked out the rest of the image."}),"\n",(0,n.jsx)(t.li,{children:"LIME displayed the whole image, highlighting in green the parts it deemed most important to the model."}),"\n",(0,n.jsx)(t.li,{children:"Shapley displayed its explanations with a heat map, overlaying the image with blue and red squares whose brightness indicated the importance of the pixel group in the model's decision."}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:"The different data representations all have their pros and cons (Shapley can convey more information by having more values pixel groups can take, but the others tend to be less cluttered and more intuitive explanations), but ideally these would be standardized to be able to directly compare the explaining techniques."}),"\n",(0,n.jsx)(t.h3,{id:"superpixels-vs-pixel-groups",children:"Superpixels vs. pixel groups"}),"\n",(0,n.jsx)(t.p,{children:"All three explanations techniques need to merge pixels together to be computationally feasible, and in an ideal world the techniques would have used the same condensation algorithms to remove this as a confounding variable. Unfortunately, Shapley splits the image into a grid of squares, while LIME and Anchoring use superpixelation algorithms to group like pixels into shapes. The Anchoring and LIME packages also use different superpixelation algorithms, meaning that they do not have the same set of possible explanations, which would be ideal for evaluating them head to head."})]})}function h(e={}){const{wrapper:t}={...(0,s.M)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(p,{...e})}):p(e)}},2172:(e,t,i)=>{i.d(t,{I:()=>r,M:()=>o});var n=i(1504);const s={},a=n.createContext(s);function o(e){const t=n.useContext(a);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),n.createElement(a.Provider,{value:t},e.children)}}}]);