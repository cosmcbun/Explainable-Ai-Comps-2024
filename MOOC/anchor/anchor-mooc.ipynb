{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#local file path adjustments\n",
    "import sys\n",
    "sys.path.append('C:/Users/Thomas/Desktop/comps/Explainable-Ai-Comps-2024/mooc/src/')\n",
    "\n",
    "#imports for models\n",
    "import svc\n",
    "import mlp\n",
    "import data_loader\n",
    "\n",
    "#imports for Anchor\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import sys\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/Thomas/Desktop/comps/Explainable-Ai-Comps-2024/mooc/src\\data_loader.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['gender']] = integer_encoded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00e+00, 0.00e+00, 0.00e+00, ..., 1.90e+01, 0.00e+00, 1.30e+01],\n",
       "        [1.00e+00, 1.00e+00, 1.00e-02, ..., 2.40e+01, 2.00e+00, 7.10e+01],\n",
       "        [1.00e+00, 1.00e+00, 0.00e+00, ..., 3.00e+01, 0.00e+00, 1.09e+02],\n",
       "        ...,\n",
       "        [1.00e+00, 1.00e+00, 0.00e+00, ..., 3.30e+01, 0.00e+00, 5.70e+01],\n",
       "        [0.00e+00, 0.00e+00, 0.00e+00, ..., 1.80e+01, 0.00e+00, 1.33e+02],\n",
       "        [0.00e+00, 1.00e+00, 0.00e+00, ..., 2.30e+01, 0.00e+00, 7.20e+01]]),\n",
       " array([[0.00e+00, 1.00e+00, 0.00e+00, ..., 2.40e+01, 0.00e+00, 3.00e+01],\n",
       "        [0.00e+00, 1.00e+00, 0.00e+00, ..., 2.30e+01, 0.00e+00, 1.66e+02],\n",
       "        [1.00e+00, 1.00e+00, 1.00e-02, ..., 2.50e+01, 1.00e+00, 2.11e+02],\n",
       "        ...,\n",
       "        [1.00e+00, 1.00e+00, 0.00e+00, ..., 3.10e+01, 0.00e+00, 3.50e+01],\n",
       "        [1.00e+00, 1.00e+00, 0.00e+00, ..., 2.00e+01, 2.00e+00, 6.50e+01],\n",
       "        [1.00e+00, 1.00e+00, 0.00e+00, ..., 2.30e+01, 0.00e+00, 1.66e+02]]),\n",
       " 32669    0\n",
       " 33718    0\n",
       " 36256    0\n",
       " 40061    0\n",
       " 2534     0\n",
       "         ..\n",
       " 28541    0\n",
       " 13121    0\n",
       " 18969    0\n",
       " 44058    0\n",
       " 38605    0\n",
       " Name: Completed_or_Not, Length: 46364, dtype: int64,\n",
       " 43928    0\n",
       " 7997     0\n",
       " 1868     0\n",
       " 37011    0\n",
       " 18052    0\n",
       "         ..\n",
       " 38435    0\n",
       " 3874     0\n",
       " 20114    0\n",
       " 3589     0\n",
       " 28444    0\n",
       " Name: Completed_or_Not, Length: 11591, dtype: int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = data_loader.DataLoader()\n",
    "dl.load(path='C:/Users/Thomas/Desktop/comps/Explainable-Ai-Comps-2024/MOOC/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_model = svc.SVC('C:/Users/Thomas/Desktop/comps/Explainable-Ai-Comps-2024/MOOC/src/MITx-SVC.pkl', from_file=True)\n",
    "\n",
    "#svc_model.build(dl.X_train, dl.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Thomas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_model = mlp.MLPClassifier('C:/Users/Thomas/Desktop/comps/Explainable-Ai-Comps-2024/MOOC/src/MITx-MLP.pkl', from_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing ANCHOR\n",
    "MOOC_feature_names = ['viewed', 'gender',   'grade',    'nevents', 'ndays_act', 'nplay_video',  'nchapters',    'age',  'votes',    'num_words'] #thanks Lev\n",
    "\n",
    "MOOC_categorical_names = {\n",
    "    0: ['not viewed', 'viewed'],\n",
    "    1: ['m', 'f'],\n",
    "    2: ['grade -- non cat'],\n",
    "    3: ['nevents -- non cat'],\n",
    "    4: ['ndays_act -- non cat'],\n",
    "    5: ['nplay_video -- non cat'],\n",
    "    6: ['nchapters -- non cat'],\n",
    "    7: ['age -- non cat'],\n",
    "    8: ['votes -- non cat'],\n",
    "    9: ['num_words -- non cat']\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# MOOC_categorical_names = {\n",
    "#     0: ['Not Viewed','Viewed'],\n",
    "#     1: ['Male', 'Female'],\n",
    "#     2: ['grade?'],\n",
    "#     3: ['ndays_act?'],\n",
    "#     4: ['nplay_video?'],\n",
    "#     5: ['nchapters?'],\n",
    "#     6: ['age?'],\n",
    "#     7: ['votes?'],\n",
    "#     8: ['num words cat?'],\n",
    "#     9: ['I dont even know?']\n",
    "#     }\n",
    "\n",
    "X_headers = MOOC_feature_names = ['viewed', 'gender',   'grade',    'nevents', 'ndays_act', 'nplay_video',  'nchapters',    'age',  'votes',    'num_words']\n",
    "\n",
    "explainer = anchor_tabular.AnchorTabularExplainer([0,1],X_headers,dl.X_train, categorical_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "Prediction: [0]\n",
      "Prediction:  0\n",
      "Prediction:  0\n",
      "X_train[idx]: [0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 1.97757e+05\n",
      " 0.00000e+00 2.00000e+01 0.00000e+00 3.80000e+01]\n",
      "Shape of X_train: (46364, 10)\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "np.random.seed(1)\n",
    "\n",
    "dummy_val1 = np.array([[1, 0, 0.92, 11000, 32, 197757, 4, 22, 8, 1000]])\n",
    "dummy_val2 = np.array([[1, 0, 0.99, 11000, 32, 197757, 4, 22, 8, 1000]])\n",
    "\n",
    "print(\"Prediction:\", svc_model.predict(dummy_val1))\n",
    "print(\"Prediction:\", svc_model.predict(dummy_val2))\n",
    "\n",
    "print('Prediction: ', explainer.class_names[svc_model.predict(dummy_val1)[0]])\n",
    "print('Prediction: ', explainer.class_names[svc_model.predict(dummy_val2)[0]])\n",
    "\n",
    "def predict_svm_0(inp):\n",
    "  return svc_model.predict(inp)[0]\n",
    "\n",
    "\n",
    "print(\"X_train[idx]:\", dl.X_train[idx])\n",
    "print(\"Shape of X_train:\", dl.X_train.shape)\n",
    "\n",
    "exp = explainer.explain_instance(dummy_val1, svc_model.predict, threshold=0.95)\n",
    "\n",
    "\n",
    "print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "threshold = 0.95\n",
    "print('Prediction: ', explainer.class_names[svc_model.predict(dummy_val1.reshape(1, -1))[0]])\n",
    "exp = explainer.explain_instance(dummy_val1, svc_model.predict, threshold=0.95)\n",
    "\n",
    "print('Precision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    ['fail','pass'], #class names\n",
    "    MOOC_feature_names, #feature names\n",
    "    dl.X_train, #training data\n",
    "    MOOC_categorical_names #categorical names)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.81\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 1.00\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 1.00\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.81\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.81\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  1\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.81\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 1.00\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 1.00\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 1.00\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.80\n",
      "Prediction:  0\n",
      "Anchor: grade <= 0.00\n",
      "Precision: 1.00\n",
      "Coverage: 0.81\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n",
      "Anchor: \n",
      "Precision: 0.99\n",
      "Coverage: 1.00\n",
      "Prediction:  0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;124m'\u001b[39m, prediction)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvc_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnchor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AND \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(exp\u001b[38;5;241m.\u001b[39mnames())))\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m exp\u001b[38;5;241m.\u001b[39mprecision())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anchor\\anchor_tabular.py:282\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.explain_instance\u001b[1;34m(self, data_row, classifier_fn, threshold, delta, tau, batch_size, max_anchor_size, desired_label, beam_size, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# return sample_fn, mapping\u001b[39;00m\n\u001b[0;32m    278\u001b[0m exp \u001b[38;5;241m=\u001b[39m anchor_base\u001b[38;5;241m.\u001b[39mAnchorBaseBeam\u001b[38;5;241m.\u001b[39manchor_beam(\n\u001b[0;32m    279\u001b[0m     sample_fn, delta\u001b[38;5;241m=\u001b[39mdelta, epsilon\u001b[38;5;241m=\u001b[39mtau, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    280\u001b[0m     desired_confidence\u001b[38;5;241m=\u001b[39mthreshold, max_anchor_size\u001b[38;5;241m=\u001b[39mmax_anchor_size,\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_names_to_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_row\n\u001b[0;32m    284\u001b[0m exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m classifier_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_fn(data_row\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anchor\\anchor_tabular.py:312\u001b[0m, in \u001b[0;36mAnchorTabularExplainer.add_names_to_exp\u001b[1;34m(self, data_row, hoeffding_exp, mapping)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_names:\n\u001b[0;32m    311\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(v)\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    313\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_names[f][v]):\n\u001b[0;32m    314\u001b[0m         fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    315\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (fname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategorical_names[f][v])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "np.random.seed(1)\n",
    "for i in range(100):\n",
    "    prediction = explainer.class_names[svc_model.predict(dl.X_test[i].reshape(1, -1))[0]]\n",
    "    print('Prediction: ', prediction)\n",
    "    if(prediction == 0):\n",
    "        exp = explainer.explain_instance(dl.X_test[i], svc_model.predict, threshold=0.95)\n",
    "        print('Anchor: %s' % (' AND '.join(exp.names())))\n",
    "        print('Precision: %.2f' % exp.precision())\n",
    "        print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
