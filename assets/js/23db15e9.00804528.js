"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[3832],{3324:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var a=n(7624),s=n(2172);const i={},o="ResNet",r={id:"LIME/ResNet",title:"ResNet",description:"Can you explain your answer?",source:"@site/docs/LIME/ResNet.md",sourceDirName:"LIME",slug:"/LIME/ResNet",permalink:"/Explainable-Ai-Comps-2024/LIME/ResNet",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/LIME/ResNet.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/Explainable-Ai-Comps-2024/LIME/Introduction"},next:{title:"Shapley Values",permalink:"/Explainable-Ai-Comps-2024/category/shapley-values"}},l={},c=[{value:"Can you explain your answer?",id:"can-you-explain-your-answer",level:2},{value:"Cartons and Vipers and Bears, oh my!",id:"cartons-and-vipers-and-bears-oh-my",level:2},{value:"What does this tell us about LIME?",id:"what-does-this-tell-us-about-lime",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",p:"p",...(0,s.M)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h1,{id:"resnet",children:"ResNet"}),"\n",(0,a.jsx)(t.h2,{id:"can-you-explain-your-answer",children:"Can you explain your answer?"}),"\n",(0,a.jsx)(t.p,{children:"(Introduce ResNet as an ML model that predicts a class based on an image input. Also introduce cats/dogs dataset, and how LIME can explain ResNet's predictions using an easier example)"}),"\n",(0,a.jsx)(t.p,{children:"Generating explanations with LIME is fun and all, but in order to generate an explanation, we must first find a model that we can explain in the first place."}),"\n",(0,a.jsxs)(t.p,{children:["Enter ",(0,a.jsx)(t.a,{href:"https://pytorch.org/hub/pytorch_vision_resnet/",children:"ResNet"})," (Residual Neural Network), an architecture trained on the image classification dataset known as ",(0,a.jsx)(t.a,{href:"https://www.image-net.org/",children:"ImageNet"}),". ResNet is trained on millions of different images to identify the subjects of a wide range of different classes. For the purpose of our project, we chose to use the pretrained model to focus specifically on identifying pictures of cats and dogs (of which we found several thousand images)."]}),"\n",(0,a.jsx)(t.p,{children:"The way LIME works with ResNet is relatively simple: you take an image, resize it to match the specifications (we resized them to be 224x224 squares), transform the image to tensors and normalize. Once this is finished, it's a simple matter to get the prediction and train a LimeImageExplainer() model, which will apply a mask that highlights the parts of the image that contribute to (green) or against (red) ResNet's prediction. An example can be seen below:"}),"\n",(0,a.jsx)(t.p,{children:"(insert example image here)"}),"\n",(0,a.jsx)(t.p,{children:"(explain example)"}),"\n",(0,a.jsx)(t.h2,{id:"cartons-and-vipers-and-bears-oh-my",children:"Cartons and Vipers and Bears, oh my!"}),"\n",(0,a.jsx)(t.p,{children:"(talk about how LIME can explain some of the wackier ResNet predictions)"}),"\n",(0,a.jsx)(t.h2,{id:"what-does-this-tell-us-about-lime",children:"What does this tell us about LIME?"}),"\n",(0,a.jsx)(t.p,{children:"(speak more generally about LIME and how it interacts with the dataset from a critical analysis pov)"})]})}function h(e={}){const{wrapper:t}={...(0,s.M)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},2172:(e,t,n)=>{n.d(t,{I:()=>r,M:()=>o});var a=n(1504);const s={},i=a.createContext(s);function o(e){const t=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),a.createElement(i.Provider,{value:t},e.children)}}}]);