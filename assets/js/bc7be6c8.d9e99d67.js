"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[5328],{6392:(e,s,a)=>{a.r(s),a.d(s,{assets:()=>h,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>o});var t=a(7624),n=a(2172);const i={},l="MOOC: Comparative Results",r={id:"User Study/MOOC - Comparative Results",title:"MOOC: Comparative Results",description:'"It really breaks down the idea of the black box model."',source:"@site/docs/User Study/MOOC - Comparative Results.md",sourceDirName:"User Study",slug:"/User Study/MOOC - Comparative Results",permalink:"/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/User Study/MOOC - Comparative Results.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Quote Takeaways",permalink:"/Explainable-Ai-Comps-2024/User Study/Quote Takeaways"},next:{title:"Methodology of the MOOC user study",permalink:"/Explainable-Ai-Comps-2024/User Study/MOOC - Methodology"}},h={},o=[{value:"&quot;It really breaks down the idea of the black box model.&quot;",id:"it-really-breaks-down-the-idea-of-the-black-box-model",level:2},{value:"Shapley Values \u2014 Math vs. Intuition",id:"shapley-values--math-vs-intuition",level:2},{value:"Example B",id:"example-b",level:2},{value:"Example C",id:"example-c",level:2},{value:"Example D",id:"example-d",level:2},{value:"Example E",id:"example-e",level:2},{value:"Example F",id:"example-f",level:2},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const s={a:"a",annotation:"annotation",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",math:"math",mn:"mn",mo:"mo",mrow:"mrow",p:"p",semantics:"semantics",span:"span",ul:"ul",...(0,n.M)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.h1,{id:"mooc-comparative-results",children:"MOOC: Comparative Results"}),"\n",(0,t.jsx)(s.h2,{id:"it-really-breaks-down-the-idea-of-the-black-box-model",children:'"It really breaks down the idea of the black box model."'}),"\n",(0,t.jsxs)(s.p,{children:["Most participants felt that any of these techniques sufficiently explained how a model came to its decision. This implies that any of these methods may be effectively employed in accordance with the ",(0,t.jsx)(s.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/The%20EU's%20right%20to%20explainability",children:"EU's GDPR"}),"."]}),"\n",(0,t.jsx)(s.p,{children:"These techniques were difficult to explain in such a short time, and a lack of understanding in each of the methods lead to each user heavily weighing visualizations over theoretical basis. This also lead to many participants to generalize each technique across multiple instances, which while not necessarily problematic, does lessen the effect of each explanation's foundation."}),"\n",(0,t.jsx)(s.p,{children:"Overall, Shapley values ranked at the top of the users' preferences and trust, followed by LIME, with Anchor tending to be the least preferred.  We also found that the order in which each XAI technique a participant was shown had a significant impact on their preference and perception of the XAI techniques."}),"\n",(0,t.jsx)(s.h2,{id:"shapley-values--math-vs-intuition",children:"Shapley Values \u2014 Math vs. Intuition"}),"\n",(0,t.jsx)(s.p,{children:"Shapley values pulled ahead in our user study by quite a bit: they were most trusted (85%, 23% above its nearest competitor), and they were also the favorite technique of 65% of our users. Moreover, Shapley values accrued an average understandability of 4.17, more than half a point over the other techniques."}),"\n",(0,t.jsxs)(s.p,{children:["Multiple users noted Shapley values' intuition, specifically the additive nature of the ",(0,t.jsx)(s.code,{children:"shap"})," package's arrow visuals (as shown in ",(0,t.jsx)(s.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley%20and%20MOOC",children:"Shapley and MOOC"}),")"]}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:"\u201cBig arrow go right. I like. Sum of big arrows insufficient to allow positive prediction.\u201d"}),"\n",(0,t.jsx)(s.li,{children:'"It feels like the method gave me an explanation, and the researcher presenting it didn\u2019t really need to help me.'}),"\n",(0,t.jsx)(s.li,{children:'"This makes sense, like the bars moving further and closer. It feels more cumulative"'}),"\n",(0,t.jsx)(s.li,{children:'"Shapley had the arrows showing which way, which was very easy to understand."'}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["While Shapley values were visually intuitive, its extensive ",(0,t.jsx)(s.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley's%20Math",children:"mathematical basis"})," was almost entirely disregarded. In fact, many users noted that Shapley's math restricted was confusing, and that it restricted the kinds of questions they were able to answer:"]}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsx)(s.li,{children:'"I don\u2019t have enough of a base knowledge in the math for Shapley. When you told me the numbers and what represents what, I just was not able to follow."'}),"\n",(0,t.jsx)(s.li,{children:'"It\u2019s doing a good job of explaining what happened, but not how it comes to conclusions."'}),"\n",(0,t.jsx)(s.li,{children:'"We can\u2019t get the threshold/how much better it gets when there are more plays [nplay_video]. The overall impact is kind of missing here."'}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:"Ultimately, the study showed that although Shapley values lend themselves to intuitive visualizations, its math is either disregarded or detrimental to the overall understanding of the technique."}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsx)(s.p,{children:'"With Shapley, I don\u2019t get the math, but I intuitively get it."'}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["Intruigingly, users found Shapley values to be both more understandable and more explainable when the technique explained why a machine learning model was ",(0,t.jsx)(s.em,{children:"incorrect"})," (",(0,t.jsxs)(s.span,{className:"katex",children:[(0,t.jsx)(s.span,{className:"katex-mathml",children:(0,t.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(s.semantics,{children:[(0,t.jsxs)(s.mrow,{children:[(0,t.jsx)(s.mn,{children:"3.94"}),(0,t.jsx)(s.mo,{children:"\u2192"}),(0,t.jsx)(s.mn,{children:"4.33"})]}),(0,t.jsx)(s.annotation,{encoding:"application/x-tex",children:"3.94\\rightarrow4.33"})]})})}),(0,t.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"3.94"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,t.jsx)(s.span,{className:"mrel",children:"\u2192"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"4.33"})]})]})]})," and ",(0,t.jsxs)(s.span,{className:"katex",children:[(0,t.jsx)(s.span,{className:"katex-mathml",children:(0,t.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(s.semantics,{children:[(0,t.jsxs)(s.mrow,{children:[(0,t.jsx)(s.mn,{children:"3.54"}),(0,t.jsx)(s.mo,{children:"\u2192"}),(0,t.jsx)(s.mn,{children:"3.66"})]}),(0,t.jsx)(s.annotation,{encoding:"application/x-tex",children:"3.54\\rightarrow3.66"})]})})}),(0,t.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"3.54"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,t.jsx)(s.span,{className:"mrel",children:"\u2192"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"3.66"})]})]})]}),", respectively). There are many possibilities which may explain this."]}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["Firstly, when a model is incorrect, people may be more desperate for an explanation, no matter its source. We see a massive uptick in LIME's understandability as well under these circumstances (",(0,t.jsxs)(s.span,{className:"katex",children:[(0,t.jsx)(s.span,{className:"katex-mathml",children:(0,t.jsx)(s.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(s.semantics,{children:[(0,t.jsxs)(s.mrow,{children:[(0,t.jsx)(s.mn,{children:"3.25"}),(0,t.jsx)(s.mo,{children:"\u2192"}),(0,t.jsx)(s.mn,{children:"4.13"})]}),(0,t.jsx)(s.annotation,{encoding:"application/x-tex",children:"3.25\\rightarrow4.13"})]})})}),(0,t.jsxs)(s.span,{className:"katex-html","aria-hidden":"true",children:[(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"3.25"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,t.jsx)(s.span,{className:"mrel",children:"\u2192"}),(0,t.jsx)(s.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,t.jsxs)(s.span,{className:"base",children:[(0,t.jsx)(s.span,{className:"strut",style:{height:"0.6444em"}}),(0,t.jsx)(s.span,{className:"mord",children:"4.13"})]})]})]}),"), which has the lowest understandability in situations where the model is correct. This is potentially refuted by Anchors' scores, which decrease on both fronts when moving from correct to incorrect predictions."]}),"\n",(0,t.jsxs)(s.li,{children:["Secondly, while the ordering of our techniques was randomized, our samples were ordered such that the incorrect results are much more present in the latter half of the survey. This would allow users to become more acquainted with ",(0,t.jsx)(s.em,{children:"all"})," of the techniques, thus leading to higher understandability/explainability across the board. However, LIME's explainability and Anchors' understandability/explainability drop, even with this ordering."]}),"\n",(0,t.jsx)(s.li,{children:'Thirdly, and most probably, due to the small nature of the study, individual users may have a much higher impact on the average outcomes. One user specifically noted that they were "afraid of extremes," and marked mostly within the 2-4 range instead of reporting 1s or 5s, while another responded predominantly at the poles. Due to the small number of users, such varying survey styles can cause much more variation in the results, leading to pattern hallucination.'}),"\n"]}),"\n",(0,t.jsx)(s.h2,{id:"example-b",children:"Example B"}),"\n",(0,t.jsx)(s.h2,{id:"example-c",children:"Example C"}),"\n",(0,t.jsx)(s.h2,{id:"example-d",children:"Example D"}),"\n",(0,t.jsx)(s.h2,{id:"example-e",children:"Example E"}),"\n",(0,t.jsx)(s.h2,{id:"example-f",children:"Example F"}),"\n",(0,t.jsx)(s.h2,{id:"conclusion",children:"Conclusion"})]})}function d(e={}){const{wrapper:s}={...(0,n.M)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},2172:(e,s,a)=>{a.d(s,{I:()=>r,M:()=>l});var t=a(1504);const n={},i=t.createContext(n);function l(e){const s=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:l(e.components),t.createElement(i.Provider,{value:s},e.children)}}}]);