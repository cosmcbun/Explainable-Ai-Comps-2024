<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Shapley Values/The EU's right to explainability" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">The EU&#x27;s Right to Explainability | Explainable AI: Breaking Down the Black Box</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="The EU&#x27;s Right to Explainability | Explainable AI: Breaking Down the Black Box"><meta data-rh="true" name="description" content="(Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)"><meta data-rh="true" property="og:description" content="(Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)"><link data-rh="true" rel="icon" href="/Explainable-Ai-Comps-2024/img/carleton-enhanced.ico"><link data-rh="true" rel="canonical" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability" hreflang="en"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/Explainable-Ai-Comps-2024/assets/css/styles.2f687a26.css">
<script src="/Explainable-Ai-Comps-2024/assets/js/runtime~main.0d99401d.js" defer="defer"></script>
<script src="/Explainable-Ai-Comps-2024/assets/js/main.1451e3ef.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Explainable-Ai-Comps-2024/"><div class="navbar__logo"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Explainable AI: Breaking Down the Black Box</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Explainable-Ai-Comps-2024/category/introduction">Writeup</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/introduction">Introduction</a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/methodology">Methodology</a><button aria-label="Expand sidebar category &#x27;Methodology&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/lime">LIME</a><button aria-label="Expand sidebar category &#x27;LIME&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/Explainable-Ai-Comps-2024/category/shapley-values">Shapley Values</a><button aria-label="Collapse sidebar category &#x27;Shapley Values&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC">Shapley and MOOC</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet">Applying Shapley to the ResNet network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley&#x27;s Math">Shapley&#x27;s Math</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability">The EU&#x27;s Right to Explainability</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/anchors">Anchors</a><button aria-label="Expand sidebar category &#x27;Anchors&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study / Results</a><button aria-label="Expand sidebar category &#x27;User Study / Results&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Citations">Citations</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/from-template">From Template</a><button aria-label="Expand sidebar category &#x27;From Template&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Explainable-Ai-Comps-2024/Intractivitity/hello_world">Intractivitity</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Posters">Posters</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Explainable-Ai-Comps-2024/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Explainable-Ai-Comps-2024/category/shapley-values"><span itemprop="name">Shapley Values</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">The EU&#x27;s Right to Explainability</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>The EU&#x27;s Right to Explainability</h1>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="disclaimer-none-on-this-team-are-certified-lawyers-this-is-an-exploration-of-shapley-as-a-concept-and-is-not-legal-advice">(Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)<a href="#disclaimer-none-on-this-team-are-certified-lawyers-this-is-an-exploration-of-shapley-as-a-concept-and-is-not-legal-advice" class="hash-link" aria-label="Direct link to (Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)" title="Direct link to (Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)">​</a></h4>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>In section 9.5 of his textbook <em>Interpretable Machine Learning</em>, Christoph Molnar speculates that Shapley Values may currently be the only valid legal defense when explaining a machine learning model:</p>
<blockquote>
<p>In situations where the law requires explainability – like EU’s “right to explanations” – the Shapley value might be the only legally compliant method, because it is based on a solid theory and distributes the effects fairly. I am not a lawyer, so this reflects only my intuition about the requirements. <a href="https://christophm.github.io/interpretable-ml-book/shapley.html" target="_blank" rel="noopener noreferrer">(Molnar 2023)</a></p>
</blockquote>
<p>This may well be true, as Shapley&#x27;s method is the only technique supported by proof-based math,
and as the calculations make little to no assumptions about the data or model itself. However, the European Union&#x27;s articles on the <em>Right to Explanation</em> are fairly vague as to what kinds of explanation would truly suffice.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="shapleys-legality-as-an-explanation">Shapley&#x27;s legality as an explanation<a href="#shapleys-legality-as-an-explanation" class="hash-link" aria-label="Direct link to Shapley&#x27;s legality as an explanation" title="Direct link to Shapley&#x27;s legality as an explanation">​</a></h2>
<p>After a full review of all articles pertaining to the EU&#x27;s <a href="https://artificialintelligenceact.eu/" target="_blank" rel="noopener noreferrer">Artificial Intelligence Act</a>, the Scientific Foresight Unit (STOA) of the European Parliamentary Research Service declares nine pillars of explanation that an AI Technique must uphold:</p>
<blockquote>
<ol>
<li>information on the existence of profiling, i.e., on the fact that the data subject will be
profiled or is already being profiled;</li>
<li>general information on the purposes of the profiling and decision-making;</li>
<li>general information on the kind of approach and technology that is adopted;</li>
<li>general information on what inputs factors (predictors) and outcomes
(targets/predictions), of what categories are being considered;</li>
<li>general information on the relative importance of such input factors in determining the
outcomes;</li>
<li>specific information on what data have been collected about the data subject and used
for profiling him or her;</li>
<li>specific information on what values for the features of the data subject determined the
outcome concerning him or her;</li>
<li>specific information on what data have been inferred about the data subject;</li>
<li>specific information on the inference process through which certain values for the
features of the data subject have determined a certain outcome concerning him or her. <br>
<a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU(2020)641530_EN.pdf" target="_blank" rel="noopener noreferrer">(STOA 2020, p.62-66)</a></li>
</ol>
</blockquote>
<p>Sections 1-5 require access to the model&#x27;s training data, which Shapley&#x27;s initial method allows, but it does not typically address the data which is not local to the prediction of focus . Due to the generalizability of the base technique to a global interpretable example, however, all five criteria may potentially be met. If not, the <a href="https://arxiv.org/abs/1904.02868" target="_blank" rel="noopener noreferrer">Data Shapley</a> variant would best fit such explanations while still maintaining the original mathematical principles of the base.</p>
<p>Sections 5-9 are able to be addressed post-hoc, which all of our explainable techniques are able to provide with varying degrees of infallibility. What is important here, though, is that Shapley values can provide all required explanations, as demonstrated in our page on the calculation of Shapley values. </p>
<h1>Are Shapley values always optimal, then?</h1>
<p>While the mathematical backing for Shapley values is quite strong, it is not entirely necessary to hold up in court. Each of the techniques we display are able to satisfy most if not all of these demands with relatively few assumptions about the model and the data. In the same review, the STOA concluded that each explanation must at least provide the user an explanation of &quot;the specific information that most matters <em>to them</em>, namely, with the information on what values for their
features determined in their case an unfavourable outcome&quot; <a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU(2020)641530_EN.pdf" target="_blank" rel="noopener noreferrer">(STOA 2020, p.65)</a>.
Not only can these rules apply to each of our techniques of focus with or without justification through coalitional game theory, but the specific qualification that the technique must specifically satisfy the requestor of the explanation implies that a &quot;legal explanation&quot; constitutes nothing more than &quot;what a user accepts.&quot;</p>
<p>This was one of the inspirations for our <a href="/Explainable-Ai-Comps-2024/category/user-study--results/"><em>user study</em></a>: to gauge the relative understandability and trustworthiness of each of our three techniques.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/Shapley Values/The EU&#x27;s right to explainability.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley&#x27;s Math"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Shapley&#x27;s Math</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Explainable-Ai-Comps-2024/category/anchors"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Anchors</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#disclaimer-none-on-this-team-are-certified-lawyers-this-is-an-exploration-of-shapley-as-a-concept-and-is-not-legal-advice" class="table-of-contents__link toc-highlight">(Disclaimer: none on this team are certified lawyers. This is an exploration of Shapley as a concept and is not legal advice)</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#shapleys-legality-as-an-explanation" class="table-of-contents__link toc-highlight">Shapley&#39;s legality as an explanation</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Our Project</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Introduction">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Methodology">Methodology</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/Citations">Citations</a></li></ul></div><div class="col footer__col"><div class="footer__title">XAI Techniques</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/LIME">LIME</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Shapley-values">Shapley values</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Anchors">Anchors</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Repository<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Carleton College XAI Group | Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>