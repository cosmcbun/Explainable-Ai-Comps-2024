"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[3456],{8828:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>h,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>r,toc:()=>c});var n=s(7624),t=s(2172);const l={"sidebar-position":4},i="Shapley and MOOC",r={id:"Shapley Values/Shapley and MOOC",title:"Shapley and MOOC",description:"This section discusses the application of the `shap` package to the Multi-Layer Perceptron that we built for the MOOC dataset. For image data, please refer to Shapley and ResNet",source:"@site/docs/Shapley Values/Shapley and MOOC.md",sourceDirName:"Shapley Values",slug:"/Shapley Values/Shapley and MOOC",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/Shapley Values/Shapley and MOOC.md",tags:[],version:"current",frontMatter:{"sidebar-position":4},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Introduction"},next:{title:"Shapley and Resnet",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet"}},h={},c=[{value:"The Code",id:"the-code",level:2},{value:"Explaining a single datapoint",id:"explaining-a-single-datapoint",level:2}];function o(e){const a={a:"a",annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",img:"img",math:"math",mi:"mi",mn:"mn",mo:"mo",mrow:"mrow",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",...(0,t.M)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.h1,{id:"shapley-and-mooc",children:"Shapley and MOOC"}),"\n",(0,n.jsxs)(a.p,{children:["This section discusses the application of the ",(0,n.jsx)(a.code,{children:"shap"})," package to the Multi-Layer Perceptron that we built for the MOOC dataset. For image data, please refer to ",(0,n.jsx)(a.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley%20and%20Resnet",children:(0,n.jsx)(a.em,{children:"Shapley and ResNet"})})]}),"\n",(0,n.jsx)(a.h2,{id:"the-code",children:"The Code"}),"\n",(0,n.jsxs)(a.p,{children:["We calculate Shapley values for our dataset via Python's ",(0,n.jsx)(a.code,{children:"shap"})," package, a library of functions and classes which encompasses virtually all possible variations upon Lloyd Shapley's original analysis."]}),"\n",(0,n.jsx)(a.p,{children:"Due to its massive popularity, this package was quite convenient, requiring only a few lines to set up. First, we build our model (see more about our model here)\nand create an Explainer object for it."}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-Python",children:"import shap\n# Create our ML model:\nmodel = MultiLayerPerceptron()\n# Create our explainer:\nexplainer = shap.explainers.Permutation(\n  model.predict_proba, \n  X_train, \n  feature_names=feature_names)\n"})}),"\n",(0,n.jsxs)(a.p,{children:["This is a ",(0,n.jsx)(a.code,{children:"Permutation"})," explainer, which builds all possible permutations of feature-value coalitions for the approximation of each Shapley value. The creation of such coalitions mirrors the base technique as outlined in the ",(0,n.jsx)(a.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley's%20Math",children:"Shapley's Math"})," page.\nWe use our model's ",(0,n.jsx)(a.code,{children:"predict_proba"}),' function to return real-valued probabilities for the classes "Course Completed" and "Dropped Out," and we pass in our training data ',(0,n.jsx)(a.code,{children:"X_train"}),' as our data matrix from which our explainer will pull substitute feature values in order to simulate each feature "not participating" in the game of predicton (See our explanation of features "not playing" in ',(0,n.jsx)(a.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley's%20Math",children:(0,n.jsx)(a.em,{children:"Shapley's Math"})}),")."]}),"\n",(0,n.jsx)(a.p,{children:"Next, we run our explainer on the datapoints that we want locally explained:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-Python",children:"# Generate Shapley values\nshapley_values = explainer(inputs)\n# Isolate the Shapley values by positive and negative probabilities\npositive_shap_vals = shapley_values[..., 1] \nnegative_shap_vals = shapley_values[..., 0]\n"})}),"\n",(0,n.jsxs)(a.p,{children:["This returns the Shapley values for each datapoint in the set of ",(0,n.jsx)(a.code,{children:"inputs"}),", as well as some useful information such as the expected (average) prediction over the set and some useful properties for ",(0,n.jsx)(a.em,{children:"Interpretable AI"}),", which we will briefly cover at the end."]}),"\n",(0,n.jsx)(a.h2,{id:"explaining-a-single-datapoint",children:"Explaining a single datapoint"}),"\n",(0,n.jsxs)(a.p,{children:["Once we have our ",(0,n.jsx)(a.code,{children:"explanations"}),", we can visualize the Shapley values for each datapoint. The ",(0,n.jsx)(a.code,{children:"shap"})," package contains a plethora of visualization tools for intepretable AI, but for the purposes of our user study and for comparison with LIME and Anchoring techniques, we used the most popular visualization for a single datapoint: the waterfall plot."]}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-Python",children:"# Generate a waterfall visualization\nshap.plots.waterfall(positive_shap_vals[i])\n"})}),"\n",(0,n.jsxs)(a.p,{children:["This returns a plot of Shapley values for the ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsx)(a.mrow,{children:(0,n.jsx)(a.mi,{children:"i"})}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"i"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.6595em"}}),(0,n.jsx)(a.span,{className:"mord mathnormal",children:"i"})]})})]}),"-th datapoint in the set, like so:"]}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"Waterfall plot of Shapley values for a datapoint i",src:s(9583).c+"",width:"832",height:"600"})}),"\n",(0,n.jsxs)(a.p,{children:["This is a visualization of the Shapley values for a positive prediction, where the probability that the person completed the course is over ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"50"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"50\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"50%"})]})})]})," (",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"59.4"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"59.4\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"59.4%"})]})})]})," in this case)."]}),"\n",(0,n.jsxs)(a.p,{children:["Our visualization begins at the bottom of the graph with the average, or expected, prediction ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mi,{children:"E"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"["}),(0,n.jsx)(a.mi,{children:"f"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"("}),(0,n.jsx)(a.mi,{children:"x"}),(0,n.jsx)(a.mo,{stretchy:"false",children:")"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"]"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"E[f(x)]"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,n.jsx)(a.span,{className:"mopen",children:"["}),(0,n.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,n.jsx)(a.span,{className:"mopen",children:"("}),(0,n.jsx)(a.span,{className:"mord mathnormal",children:"x"}),(0,n.jsx)(a.span,{className:"mclose",children:")]"})]})})]}),". In this case, the model is ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"2"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"2\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"2%"})]})})]})," confident that the student will complete the course (",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mi,{children:"E"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"["}),(0,n.jsx)(a.mi,{children:"f"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"("}),(0,n.jsx)(a.mi,{children:"x"}),(0,n.jsx)(a.mo,{stretchy:"false",children:")"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"]"}),(0,n.jsx)(a.mo,{children:"="}),(0,n.jsx)(a.mn,{children:"0.02"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"E[f(x)] = 0.02"})]})})}),(0,n.jsxs)(a.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.05764em"},children:"E"}),(0,n.jsx)(a.span,{className:"mopen",children:"["}),(0,n.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,n.jsx)(a.span,{className:"mopen",children:"("}),(0,n.jsx)(a.span,{className:"mord mathnormal",children:"x"}),(0,n.jsx)(a.span,{className:"mclose",children:")]"}),(0,n.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.jsx)(a.span,{className:"mrel",children:"="}),(0,n.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.6444em"}}),(0,n.jsx)(a.span,{className:"mord",children:"0.02"})]})]})]}),"). From here, we build upwards with respect to the relative size of the contribution to the prediction's deviation from the average: the values for the features ",(0,n.jsx)(a.code,{children:"gender"})," through ",(0,n.jsx)(a.code,{children:"viewed"})," each subtract ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"\u2264"}),(0,n.jsx)(a.mn,{children:"1"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"\\le 1\\%"})]})})}),(0,n.jsxs)(a.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.7719em",verticalAlign:"-0.136em"}}),(0,n.jsx)(a.span,{className:"mrel",children:"\u2264"}),(0,n.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"1%"})]})]})]})," from the average, while feature values from ",(0,n.jsx)(a.code,{children:"grade"})," through ",(0,n.jsx)(a.code,{children:"ndays_act"})," add between ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"4"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"4\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"4%"})]})})]})," and ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"10"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"10\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"10%"})]})})]})," to the probability."]}),"\n",(0,n.jsxs)(a.p,{children:["Finally, we see that the values for ",(0,n.jsx)(a.code,{children:"nplay_video"})," and ",(0,n.jsx)(a.code,{children:"nevents"})," are the biggest players in the game of prediction, deviating our result from the average probability prediction by ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"\u2212"}),(0,n.jsx)(a.mn,{children:"20"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"-20\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.0833em"}}),(0,n.jsx)(a.span,{className:"mord",children:"\u2212"}),(0,n.jsx)(a.span,{className:"mord",children:"20%"})]})})]})," and ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"+"}),(0,n.jsx)(a.mn,{children:"60"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"+60\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.0833em"}}),(0,n.jsx)(a.span,{className:"mord",children:"+"}),(0,n.jsx)(a.span,{className:"mord",children:"60%"})]})})]}),", respectively."]}),"\n",(0,n.jsxs)(a.p,{children:["With these features combined, our model's prediction deviates from the average by ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"+"}),(0,n.jsx)(a.mn,{children:"57.4"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"+57.4\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.0833em"}}),(0,n.jsx)(a.span,{className:"mord",children:"+"}),(0,n.jsx)(a.span,{className:"mord",children:"57.4%"})]})})]}),", yielding ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mi,{children:"f"}),(0,n.jsx)(a.mo,{stretchy:"false",children:"("}),(0,n.jsx)(a.mi,{children:"x"}),(0,n.jsx)(a.mo,{stretchy:"false",children:")"}),(0,n.jsx)(a.mo,{children:"="}),(0,n.jsx)(a.mn,{children:"0.594"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"f(x) = 0.594"})]})})}),(0,n.jsxs)(a.span,{className:"katex-html","aria-hidden":"true",children:[(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"1em",verticalAlign:"-0.25em"}}),(0,n.jsx)(a.span,{className:"mord mathnormal",style:{marginRight:"0.10764em"},children:"f"}),(0,n.jsx)(a.span,{className:"mopen",children:"("}),(0,n.jsx)(a.span,{className:"mord mathnormal",children:"x"}),(0,n.jsx)(a.span,{className:"mclose",children:")"}),(0,n.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}}),(0,n.jsx)(a.span,{className:"mrel",children:"="}),(0,n.jsx)(a.span,{className:"mspace",style:{marginRight:"0.2778em"}})]}),(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.6444em"}}),(0,n.jsx)(a.span,{className:"mord",children:"0.594"})]})]})]}),"."]}),"\n",(0,n.jsx)(a.h1,{id:"interpreting-the-model-across-the-whole-set",children:"Interpreting the model across the whole set"}),"\n",(0,n.jsxs)(a.p,{children:["One of the advantages that Shapley values have over LIME is its relative ability to globally interpret a machine learning model's input set. While this loosely adheres to ",(0,n.jsxs)(a.a,{href:"/Explainable-Ai-Comps-2024/Shapley%20Values/Shapley's%20Math",children:["Shapley values' ",(0,n.jsx)(a.strong,{children:"additivity"})," principle"]}),", it is less strongly appliccable when we are no longer dealing with individual players."]}),"\n",(0,n.jsx)(a.p,{children:"The simplest way to generate such an interpretation is to generate a bar graph of the average absolute Shapley values:"}),"\n",(0,n.jsx)(a.pre,{children:(0,n.jsx)(a.code,{className:"language-Python",children:"shap.plots.bar(shapley_values, show=False)\n"})}),"\n",(0,n.jsx)(a.p,{children:"The following example is an interpretation of the model using the MOOC dataset's test data:"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"Interpretation of multi-layer perceptron on MOOC test data",src:s(4756).c+"",width:"757",height:"568"})}),"\n",(0,n.jsxs)(a.p,{children:["As we can see, ",(0,n.jsx)(a.code,{children:"nevents"})," and ",(0,n.jsx)(a.code,{children:"nplay_video"})," are still our biggest actors in a global setting, changing the prediction by ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"\xb1"}),(0,n.jsx)(a.mn,{children:"8"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"\\pm 8\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.0833em"}}),(0,n.jsx)(a.span,{className:"mord",children:"\xb1"}),(0,n.jsx)(a.span,{className:"mord",children:"8%"})]})})]})," and ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mo,{children:"\xb1"}),(0,n.jsx)(a.mn,{children:"2"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"\\pm 2\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8333em",verticalAlign:"-0.0833em"}}),(0,n.jsx)(a.span,{className:"mord",children:"\xb1"}),(0,n.jsx)(a.span,{className:"mord",children:"2%"})]})})]}),", respectively."]}),"\n",(0,n.jsxs)(a.p,{children:["Something  most peculiar about this is that unlike our explanation of a single positive prediction, our interpretive Shapley values are much smaller globally. What the values highlight here is a strong bias towards either course completion or dropout, as a small average deviation from prediction overall must mean that the data is skewed towards one prediction. In this case, a quick examination of the data shows that in our training data, only ",(0,n.jsxs)(a.span,{className:"katex",children:[(0,n.jsx)(a.span,{className:"katex-mathml",children:(0,n.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,n.jsxs)(a.semantics,{children:[(0,n.jsxs)(a.mrow,{children:[(0,n.jsx)(a.mn,{children:"2.98"}),(0,n.jsx)(a.mi,{mathvariant:"normal",children:"%"})]}),(0,n.jsx)(a.annotation,{encoding:"application/x-tex",children:"2.98\\%"})]})})}),(0,n.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,n.jsxs)(a.span,{className:"base",children:[(0,n.jsx)(a.span,{className:"strut",style:{height:"0.8056em",verticalAlign:"-0.0556em"}}),(0,n.jsx)(a.span,{className:"mord",children:"2.98%"})]})})]})," of all students pass. As such, the model is likely achieving a high accuracy through extreme negative bias, which is why there is such low deviation from the expected prediction on average."]})]})}function m(e={}){const{wrapper:a}={...(0,t.M)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(o,{...e})}):o(e)}},4756:(e,a,s)=>{s.d(a,{c:()=>n});const n=s.p+"assets/images/shap_mooc_overall-e5de6d2c6aedf7fb4749de02dcb03073.png"},9583:(e,a,s)=>{s.d(a,{c:()=>n});const n=s.p+"assets/images/shap_mooc_tp0-71c0f3ec9b7aac4c3302ef081a87bf68.png"},2172:(e,a,s)=>{s.d(a,{I:()=>r,M:()=>i});var n=s(1504);const t={},l=n.createContext(t);function i(e){const a=n.useContext(l);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function r(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),n.createElement(l.Provider,{value:a},e.children)}}}]);