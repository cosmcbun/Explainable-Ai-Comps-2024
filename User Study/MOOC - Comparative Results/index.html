<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-User Study/MOOC - Comparative Results" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">MOOC: Comparative Results | Explainable AI: Breaking Down the Black Box</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="MOOC: Comparative Results | Explainable AI: Breaking Down the Black Box"><meta data-rh="true" name="description" content="&quot;It really breaks down the idea of the black box model.&quot;"><meta data-rh="true" property="og:description" content="&quot;It really breaks down the idea of the black box model.&quot;"><link data-rh="true" rel="icon" href="/Explainable-Ai-Comps-2024/img/carleton-enhanced.ico"><link data-rh="true" rel="canonical" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results" hreflang="en"><link data-rh="true" rel="alternate" href="https://cosmcbun.github.io/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results" hreflang="x-default"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/Explainable-Ai-Comps-2024/assets/css/styles.0e5b6101.css">
<script src="/Explainable-Ai-Comps-2024/assets/js/runtime~main.f552a200.js" defer="defer"></script>
<script src="/Explainable-Ai-Comps-2024/assets/js/main.b11b3dba.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Explainable-Ai-Comps-2024/"><div class="navbar__logo"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Explainable-Ai-Comps-2024/img/carleton logo enhanced.png" alt="Carleton College Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Explainable AI: Breaking Down the Black Box</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Explainable-Ai-Comps-2024/category/introduction">Writeup</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/Explainable-Ai-Comps-2024/About Us">About Us</a><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/introduction">Introduction</a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/methodology">Methodology</a><button aria-label="Expand sidebar category &#x27;Methodology&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/lime">LIME</a><button aria-label="Expand sidebar category &#x27;LIME&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/shapley-values">Shapley Values</a><button aria-label="Expand sidebar category &#x27;Shapley Values&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/anchors">Anchors</a><button aria-label="Expand sidebar category &#x27;Anchors&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Tumors">Tumors Case Study</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study / Results</a><button aria-label="Collapse sidebar category &#x27;User Study / Results&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/Introduction">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/Limitations">Limitations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/Quote Takeaways">Qualitative Takeaways</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/MOOC - Comparative Results">MOOC: Comparative Results</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/MOOC - Methodology">MOOC: Methodology</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/ResNet - Comparative Results">ResNet: Comparative Results</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/Explainable-Ai-Comps-2024/User Study/ResNet - Methodology">Methodology of the ResNet user study</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Explainable-Ai-Comps-2024/category/extensions">Extensions</a><button aria-label="Expand sidebar category &#x27;Extensions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Posters">Posters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Explainable-Ai-Comps-2024/Citations">Bibliography</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Explainable-Ai-Comps-2024/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/Explainable-Ai-Comps-2024/category/user-study--results"><span itemprop="name">User Study / Results</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">MOOC: Comparative Results</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>MOOC: Comparative Results</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="it-really-breaks-down-the-idea-of-the-black-box-model">&quot;It really breaks down the idea of the black box model.&quot;<a href="#it-really-breaks-down-the-idea-of-the-black-box-model" class="hash-link" aria-label="Direct link to &quot;It really breaks down the idea of the black box model.&quot;" title="Direct link to &quot;It really breaks down the idea of the black box model.&quot;">​</a></h2>
<p>Most participants felt that any of these techniques sufficiently explained how a model came to its decision. This implies that any of these methods may be effectively employed in accordance with the <a href="/Explainable-Ai-Comps-2024/Shapley Values/The EU&#x27;s right to explainability">EU&#x27;s GDPR</a>.</p>
<p>These techniques were difficult to explain in such a short time, and a lack of understanding in each of the methods lead to each user heavily weighing visualizations over theoretical basis. This also led many participants to generalize each technique across multiple instances, which while not necessarily problematic, does lessen the effect of each explanation&#x27;s foundation.</p>
<p>Overall, Shapley values ranked at the top of the users&#x27; preferences and trust, followed by LIME, with Anchor tending to be the least preferred.  We also found that the order in which each XAI technique a participant was shown had a significant impact on their preference and perception of the XAI techniques.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="technical-expertise-and-user-preference">Technical Expertise and User Preference<a href="#technical-expertise-and-user-preference" class="hash-link" aria-label="Direct link to Technical Expertise and User Preference" title="Direct link to Technical Expertise and User Preference">​</a></h2>
<!-- -->
<!-- -->
<img src="/Explainable-Ai-Comps-2024/assets/images/DoParticipantExperenceAffectRankingsOfXAITechniques-843f320ec03ebd34fd7e6d93c893c24d.png" alt="Bar Chart of XAI rankings where each bar is an experience level" style="width:600px">
<p>With such a small sample size no strong conclusions can be taken from this chart however there are a host of exploratory conclusions illustrated by this visualization.</p>
<ol>
<li>Shapley Values are the most preferred technique across participants with informal and formal experience with machine learning.</li>
<li>LIME is the most preferred technique across participants with no experience with machine learning. However, the difference between rankings from participants with no experience in ML between Shapley and LIME is trivial.</li>
<li>Anchors is the least preferred technique across all experience levels.</li>
<li>Participants with some experience in ML like Shapley values more than participants with no experience in ML.</li>
<li>The more one knows about Machine Learning the less they like Anchors</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="shapley-values--math-vs-intuition">Shapley Values — Math vs. Intuition<a href="#shapley-values--math-vs-intuition" class="hash-link" aria-label="Direct link to Shapley Values — Math vs. Intuition" title="Direct link to Shapley Values — Math vs. Intuition">​</a></h2>
<p>Shapley values pulled ahead in our user study by quite a bit: they were most trusted (85%, 23% above its nearest competitor), and they were also the favorite technique of 65% of our users. Moreover, Shapley values accrued an average understandability of 4.17, more than half a point over the other techniques.</p>
<p>Multiple users noted Shapley values&#x27; intuition, specifically the additive nature of the <code>shap</code> package&#x27;s arrow visuals (as shown in <a href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC">Shapley and MOOC</a>)</p>
<blockquote>
<ul>
<li>“Big arrow go right. I like. Sum of big arrows insufficient to allow positive prediction.”</li>
<li>&quot;It feels like the method gave me an explanation, and the researcher presenting it didn’t really need to help me.</li>
<li>&quot;This makes sense, like the bars moving further and closer. It feels more cumulative&quot;</li>
<li>&quot;Shapley had the arrows showing which way, which was very easy to understand.&quot;</li>
</ul>
</blockquote>
<p>While Shapley values were visually intuitive, its extensive <a href="/Explainable-Ai-Comps-2024/Shapley Values/Shapley&#x27;s Math">mathematical basis</a> was almost entirely disregarded. In fact, many users noted that Shapley&#x27;s math restricted was confusing, and that it restricted the kinds of questions they had hoped to answer:</p>
<blockquote>
<ul>
<li>&quot;I don’t have enough of a base knowledge in the math for Shapley. When you told me the numbers and what represents what, I just was not able to follow.&quot;</li>
<li>&quot;It’s doing a good job of explaining what happened, but not how it comes to conclusions.&quot;</li>
<li>&quot;We can’t get the threshold/how much better it gets when there are more plays [nplay_video]. The overall impact is kind of missing here.&quot;</li>
</ul>
</blockquote>
<p>Ultimately, the study showed that although Shapley values lend themselves to intuitive visualizations, its math is either disregarded or detrimental to the overall understanding of the technique.</p>
<blockquote>
<p>&quot;With Shapley, I don’t get the math, but I intuitively get it.&quot;</p>
</blockquote>
<p>Intriguingly, users found Shapley values to be both more understandable and more explainable when the technique explained why a machine learning model was <em>incorrect</em> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.94</mn><mo>→</mo><mn>4.33</mn></mrow><annotation encoding="application/x-tex">3.94\rightarrow4.33</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3.94</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4.33</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.54</mn><mo>→</mo><mn>3.66</mn></mrow><annotation encoding="application/x-tex">3.54\rightarrow3.66</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3.54</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3.66</span></span></span></span>, respectively). There are many possibilities which may explain this.</p>
<ul>
<li>Firstly, when a model is incorrect, people may be more desperate for an explanation, no matter its source. We see a massive uptick in LIME&#x27;s understandability as well under these circumstances (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3.25</mn><mo>→</mo><mn>4.13</mn></mrow><annotation encoding="application/x-tex">3.25\rightarrow4.13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3.25</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4.13</span></span></span></span>), which has the lowest understandability in situations where the model is correct. This is potentially refuted by Anchors&#x27; scores, which decrease on both fronts when moving from correct to incorrect predictions.</li>
<li>Secondly, while the ordering of our techniques was randomized, our samples were ordered such that the incorrect results are much more present in the latter half of the survey. This would allow users to become more acquainted with <em>all</em> of the techniques, thus leading to higher understandability/explainability across the board. However, LIME&#x27;s explainability and Anchors&#x27; understandability/explainability drop, even with this ordering.</li>
<li>Thirdly, and most probably, due to the small nature of the study, individual users may have a much higher impact on the average outcomes. One user specifically noted that they were &quot;afraid of extremes,&quot; and marked mostly within the 2-4 range instead of reporting 1s or 5s, while another responded predominantly at the poles. Due to the small number of users, such varying survey styles can cause much more variation in the results, leading to pattern hallucination.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="lime--the-middle-ground">LIME — The Middle Ground<a href="#lime--the-middle-ground" class="hash-link" aria-label="Direct link to LIME — The Middle Ground" title="Direct link to LIME — The Middle Ground">​</a></h2>
<p><img decoding="async" loading="lazy" alt="MOOC Trust Pie Charts" src="/Explainable-Ai-Comps-2024/assets/images/trust-24e60eead63936c1f33886558749294b.png" width="8405" height="2958" class="img_ev3q"></p>
<p>In the tabular user study, LIME was consistently in the middle of the pack. This is shown in trust (see above) and rankings. Participants who liked Anchors best ranked LIME second, and those who liked Shapley best ranked LIME second. Why is this? One theory is based on the varying expectations of participants.</p>
<p><img decoding="async" loading="lazy" alt="Three XAI Visualizations" src="/Explainable-Ai-Comps-2024/assets/images/three_explanations-a62f8031ba18bc4c82326e55e79b4f96.png" width="3156" height="1837" class="img_ev3q"></p>
<p>Some participants are looking for a set of rules to explain how/why the black box model came to its conclusions. Anchors best fulfill this expectation, and Shapley values do not attempt to meet this expectation, however the y-axis labels of LIME can communicate similar information as Anchors, though much less clearly. Therefore participants who are looking for a set of rules are likely to rank LIME in the middle, and trust LIME more than Shapley but less than Anchors.</p>
<p>Other participants (our user study suggests the majority) look for an intuitive sense of how important specific features are to the black box model&#x27;s predictions. Shapley values best fulfill this expectation, and Anchors does not attempt to meet this expectation, however the Red and Green bars of LIME can communicate similar information as Shapley, though with less consistency and nuance. Therefore participants who are looking for an intuitive sense of how important specific features are to the black box models predictions are likely to rank LIME in the middle, and trust LIME more than Anchors but less than Shapley.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/User Study/MOOC - Comparative Results.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Explainable-Ai-Comps-2024/User Study/Quote Takeaways"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Qualitative Takeaways</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Explainable-Ai-Comps-2024/User Study/MOOC - Methodology"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">MOOC: Methodology</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#it-really-breaks-down-the-idea-of-the-black-box-model" class="table-of-contents__link toc-highlight">&quot;It really breaks down the idea of the black box model.&quot;</a></li><li><a href="#technical-expertise-and-user-preference" class="table-of-contents__link toc-highlight">Technical Expertise and User Preference</a></li><li><a href="#shapley-values--math-vs-intuition" class="table-of-contents__link toc-highlight">Shapley Values — Math vs. Intuition</a></li><li><a href="#lime--the-middle-ground" class="table-of-contents__link toc-highlight">LIME — The Middle Ground</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Our Project</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Introduction">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Methodology">Methodology</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/user-study--results">User Study</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/Citations">Citations</a></li></ul></div><div class="col footer__col"><div class="footer__title">XAI Techniques</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/LIME">LIME</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Shapley-values">Shapley values</a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/category/Anchors">Anchors</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Description<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/cosmcbun/Explainable-Ai-Comps-2024/" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Repository<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/Explainable-Ai-Comps-2024/About Us">About Us</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Carleton College XAI Group | Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>