"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[696],{5988:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"XAI Techniques","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lime","href":"/Explainable-Ai-Comps-2024/XAI Techniques/LIME","docId":"XAI Techniques/LIME","unlisted":false},{"type":"link","label":"Shapley Values","href":"/Explainable-Ai-Comps-2024/XAI Techniques/Shapley","docId":"XAI Techniques/Shapley","unlisted":false},{"type":"link","label":"Anchoring","href":"/Explainable-Ai-Comps-2024/XAI Techniques/Anchors","docId":"XAI Techniques/Anchors","unlisted":false}],"href":"/Explainable-Ai-Comps-2024/category/xai-techniques"},{"type":"link","label":"User Study","href":"/Explainable-Ai-Comps-2024/User Study","docId":"User Study","unlisted":false},{"type":"link","label":"About Us","href":"/Explainable-Ai-Comps-2024/About Us","docId":"About Us","unlisted":false},{"type":"category","label":"From Template","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tutorial Intro","href":"/Explainable-Ai-Comps-2024/From Template/intro","docId":"From Template/intro","unlisted":false},{"type":"category","label":"Tutorial - Basics","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Create a Page","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/create-a-page","docId":"From Template/tutorial-basics/create-a-page","unlisted":false},{"type":"link","label":"Create a Document","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/create-a-document","docId":"From Template/tutorial-basics/create-a-document","unlisted":false},{"type":"link","label":"Create a Blog Post","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/create-a-blog-post","docId":"From Template/tutorial-basics/create-a-blog-post","unlisted":false},{"type":"link","label":"Markdown Features","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/markdown-features","docId":"From Template/tutorial-basics/markdown-features","unlisted":false},{"type":"link","label":"Deploy your site","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/deploy-your-site","docId":"From Template/tutorial-basics/deploy-your-site","unlisted":false},{"type":"link","label":"Congratulations!","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-basics/congratulations","docId":"From Template/tutorial-basics/congratulations","unlisted":false}],"href":"/Explainable-Ai-Comps-2024/category/tutorial---basics"},{"type":"category","label":"Tutorial - Extras","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Manage Docs Versions","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-extras/manage-docs-versions","docId":"From Template/tutorial-extras/manage-docs-versions","unlisted":false},{"type":"link","label":"Translate your site","href":"/Explainable-Ai-Comps-2024/From Template/tutorial-extras/translate-your-site","docId":"From Template/tutorial-extras/translate-your-site","unlisted":false}],"href":"/Explainable-Ai-Comps-2024/category/tutorial---extras"}],"href":"/Explainable-Ai-Comps-2024/category/from-template"},{"type":"category","label":"Introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Xhat is XAI?","href":"/Explainable-Ai-Comps-2024/Introduction/What is XAI","docId":"Introduction/What is XAI","unlisted":false}]},{"type":"link","label":"Numpy (Examples of images and latex in docusaurus)","href":"/Explainable-Ai-Comps-2024/numpy","docId":"numpy","unlisted":false}]},"docs":{"About Us":{"id":"About Us","title":"About Us","description":"","sidebar":"tutorialSidebar"},"From Template/intro":{"id":"From Template/intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes.","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/congratulations":{"id":"From Template/tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template.","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/create-a-blog-post":{"id":"From Template/tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed...","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/create-a-document":{"id":"From Template/tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/create-a-page":{"id":"From Template/tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/deploy-your-site":{"id":"From Template/tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack).","sidebar":"tutorialSidebar"},"From Template/tutorial-basics/markdown-features":{"id":"From Template/tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features.","sidebar":"tutorialSidebar"},"From Template/tutorial-extras/manage-docs-versions":{"id":"From Template/tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs.","sidebar":"tutorialSidebar"},"From Template/tutorial-extras/translate-your-site":{"id":"From Template/tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French.","sidebar":"tutorialSidebar"},"Introduction/What is XAI":{"id":"Introduction/What is XAI","title":"Xhat is XAI?","description":"We are living through a revolution of the standards for ethical machine learning practices which has been thoroughly marked by the need to explain artificial intelligences \u2014 namely their predictions. As discussed in Ribeiro et al. (2016, p.1), the act of explaining an AI\u2019s prediction presents the audience with visualizations pertaining to the actions it made to achieve such a decision, thus building users\u2019 trust in the model and exposing any possible errors in the model\u2019s structure. With regulations like the EU\u2019s Right to Explainability and the United States\u2019 proposed AI Bill of Rights, a machine learning model may no longer be a simple \u201cblack box\u201d: in order to prevent criminal charges, the creators of high-impact models must be able to justify each of their predictions. Over the past few years, the field has thus become inundated with approaches, each a bid for its own niche. In such an impossibly dense field, how can one quantify a method\u2019s efficacy? Which method would a jury trust?","sidebar":"tutorialSidebar"},"numpy":{"id":"numpy","title":"Numpy (Examples of images and latex in docusaurus)","description":"Packages","sidebar":"tutorialSidebar"},"User Study":{"id":"User Study","title":"User Study","description":"It is of primary importance that the group understands our three explainable AI methods. This necessitates a literature review, with papers and articles that introduce and implement Shapley and Anchor/LIME. After reading about them, we also want to implement them on complex existing models like ResNet. While the models will mostly be imported, this code base connecting existing models with existing XAI libraries will be another deliverable for our final project.","sidebar":"tutorialSidebar"},"XAI Techniques/Anchors":{"id":"XAI Techniques/Anchors","title":"Anchoring","description":"Ribeiro, Singh, and Guestrin, the original authors of LIME, also created anchoring as an Explainable AI model, which has some similarities with LIME, but outputs its explanations in a different form. Like LIME, Anchoring involves perturbing the data point in question to see how the results from the black box change. Ribeiro et al. define their anchor like so: \u201cAn anchor explanation is a rule that sufficiently \u201canchors\u201d the prediction locally \u2013 such that changes to the rest of the feature values of the instance do not matter\u201d (Ribeiro et al, 2018). For example, when evaluating the sentiment of the phrase \u201cEverything is bad\u201d, we would say that the word \u201cbad\u201d tells us that the sentiment is negative, making \u201cbad\u201d our anchor. However, if we changed the phrase to \u201cEverything is not bad\u201d, \u201cbad\u201d would not make a good anchor anymore, because the sentiment of this phrase is positive. Our new anchor would be \u201cnot bad\u201d, because these are the words that determine that the phrase is positive. The same principle can be used for multiple types of data, not just textual data. For tabular data, the algorithm will seek to find which feature values were the most important in coming to a particular decision, and for image classification the anchor will be a set of superpixels that have the most importance in determining the prediction of the model. A clear advantage of anchoring is that its output is intuitive and easy to interpret (\u201cthe sentiment of this sentence is positive because it contains the words \u2018not bad\u2019\u201d), as opposed to being a sea of coefficients.","sidebar":"tutorialSidebar"},"XAI Techniques/LIME":{"id":"XAI Techniques/LIME","title":"Lime","description":"Local Interpretable Model-Agnostic Explanations (LIME)","sidebar":"tutorialSidebar"},"XAI Techniques/Shapley":{"id":"XAI Techniques/Shapley","title":"Shapley Values","description":"Shapley value is a second post-hoc explainable AI learning method. As the name suggests, this method is named after the award-winning mathematician and game theorist Lloyd Shapley, who developed the technique back in 1953 in his original papers on cooperative game theory (Shapley et al., 1988). The method develops an explanation for machine learning models through a practical application of cooperative game theory \u2013 that is, the XAI treats each feature of an ML model as a \u201cplayer\u201d, which contributes a value that either adds or subtracts from the average prediction. This value, called the Shapley value, is calculated by looking at all possible coalitions and calculating the average marginal contributions of the given feature (i.e. the difference in predictions with and without the feature). Compared to other XAI methods, particularly LIME, this method guarantees the predictions are fairly distributed and is based on solid theory, but is computationally expensive and requires a lot more data (Molnar, 2023).","sidebar":"tutorialSidebar"}}}')}}]);