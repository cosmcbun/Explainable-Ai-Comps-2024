"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[9560],{8676:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>h});var t=s(7624),n=s(2172);const i={"sidebar-position":5},r="Applying Shapley to the ResNet network",l={id:"Shapley Values/Shapley and Resnet",title:"Shapley and Resnet",description:"\x3c!-- SOURCES:",source:"@site/docs/Shapley Values/Shapley and Resnet.md",sourceDirName:"Shapley Values",slug:"/Shapley Values/Shapley and Resnet",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Shapley and Resnet",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/Shapley Values/Shapley and Resnet.md",tags:[],version:"current",frontMatter:{"sidebar-position":5},sidebar:"tutorialSidebar",previous:{title:"Shapley and MOOC",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Shapley and MOOC"},next:{title:"Shapley's Math",permalink:"/Explainable-Ai-Comps-2024/Shapley Values/Shapley's Math"}},o={},h=[{value:"Code",id:"code",level:2},{value:"Visual Explanations",id:"visual-explanations",level:2},{value:"Required concepts",id:"required-concepts",level:3}];function c(e){const a={annotation:"annotation",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",math:"math",mi:"mi",mn:"mn",mrow:"mrow",msup:"msup",p:"p",pre:"pre",semantics:"semantics",span:"span",...(0,n.M)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.h1,{id:"applying-shapley-to-the-resnet-network",children:"Applying Shapley to the ResNet network"}),"\n",(0,t.jsxs)(a.p,{children:["This section discusses the application of the ",(0,t.jsx)(a.code,{children:"shap"})," package to the standard image-recognition architecture ResNet \u2013 both a standard version and a modified one we trained on brain tumor images."]}),"\n",(0,t.jsx)(a.h2,{id:"code",children:"Code"}),"\n",(0,t.jsxs)(a.p,{children:["Despite being very different data from MOOC's, Shapley could interpret its image data in much the same way. For the cats and dogs, for instance, our ",(0,t.jsx)(a.code,{children:"Permutation"})," explainer was created as follows:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-Python",children:'import shap\nimport torchvision.models as models\n# Import the model:\npretrained_weights = models.ResNet18_Weights.IMAGENET1K_V1\nanimal_model = models.resnet18(weights=pretrained_weights)\n# Create our explainer:\nmasker_blur = shap.maskers.Image("blur(128,128)", animal_X[0].shape)\nexplainer_blur = shap.Explainer(animal_torch_predict, masker_blur, output_names=class_names)\n'})}),"\n",(0,t.jsx)(a.p,{children:"The masker is an important part of running Shapley on images. When we produce a coalition of pixels to remain in the image, what do we do with the rest of the picture? We can't remove it, because the network always expects the same dimensions. Neither can we black it out, because sometimes that will resemble something in the image. We opted to blur the rest of the image in this project."}),"\n",(0,t.jsxs)(a.p,{children:["Then, using ",(0,t.jsx)(a.code,{children:"image_blur"}),", we explain a datapoint of our choice:"]}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-Python",children:"shap_values = explainer_blur(\n    animal_picture,\n    max_evals=eval_count, batch_size=50, outputs=shap.Explanation.argsort.flip[:top_guesses]\n)\n"})}),"\n",(0,t.jsxs)(a.p,{children:["The most important parameter here is ",(0,t.jsx)(a.code,{children:"eval_count"}),". The higher the number, the more features it will split the image into. This is, perhaps, a little strange \u2013\xa0the image already has features. In the neural network, it's got 3 features for each pixel (one per color channel); shouldn't we reuse those?"]}),"\n",(0,t.jsxs)(a.p,{children:["The problem is that Shapley's runtime is proportional to ",(0,t.jsxs)(a.span,{className:"katex",children:[(0,t.jsx)(a.span,{className:"katex-mathml",children:(0,t.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(a.semantics,{children:[(0,t.jsx)(a.mrow,{children:(0,t.jsxs)(a.msup,{children:[(0,t.jsx)(a.mn,{children:"2"}),(0,t.jsx)(a.mi,{children:"n"})]})}),(0,t.jsx)(a.annotation,{encoding:"application/x-tex",children:"2^n"})]})})}),(0,t.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(a.span,{className:"base",children:[(0,t.jsx)(a.span,{className:"strut",style:{height:"0.6644em"}}),(0,t.jsxs)(a.span,{className:"mord",children:[(0,t.jsx)(a.span,{className:"mord",children:"2"}),(0,t.jsx)(a.span,{className:"msupsub",children:(0,t.jsx)(a.span,{className:"vlist-t",children:(0,t.jsx)(a.span,{className:"vlist-r",children:(0,t.jsx)(a.span,{className:"vlist",style:{height:"0.6644em"},children:(0,t.jsxs)(a.span,{style:{top:"-3.063em",marginRight:"0.05em"},children:[(0,t.jsx)(a.span,{className:"pstrut",style:{height:"2.7em"}}),(0,t.jsx)(a.span,{className:"sizing reset-size6 size3 mtight",children:(0,t.jsx)(a.span,{className:"mord mathnormal mtight",children:"n"})})]})})})})})]})]})})]}),", where ",(0,t.jsxs)(a.span,{className:"katex",children:[(0,t.jsx)(a.span,{className:"katex-mathml",children:(0,t.jsx)(a.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,t.jsxs)(a.semantics,{children:[(0,t.jsx)(a.mrow,{children:(0,t.jsx)(a.mi,{children:"n"})}),(0,t.jsx)(a.annotation,{encoding:"application/x-tex",children:"n"})]})})}),(0,t.jsx)(a.span,{className:"katex-html","aria-hidden":"true",children:(0,t.jsxs)(a.span,{className:"base",children:[(0,t.jsx)(a.span,{className:"strut",style:{height:"0.4306em"}}),(0,t.jsx)(a.span,{className:"mord mathnormal",children:"n"})]})})]})," is the number of features. If we broke the image down into pixels, then, it'd take far too long to analyze. To this end, then, this Shapley implimentation breaks up the image into a grid with regions that are small but are still larger than a pixel."]}),"\n",(0,t.jsxs)(a.p,{children:["The other parameter here, ",(0,t.jsx)(a.code,{children:"top_guesses"}),", here specifies how many of the model's most confident answers you would like predictions for. Because the model outputs confidence for each of the thousand classes, not just the top, we can create the Shapley visualization for any class.\nWith the Shapley values in hand, we can now generate helpful visualizations."]}),"\n",(0,t.jsx)(a.h2,{id:"visual-explanations",children:"Visual Explanations"}),"\n",(0,t.jsx)(a.p,{children:(0,t.jsx)(a.img,{alt:"Cat",src:s(5020).c+"",title:"Top guesses of the model and what pixels made it choose those classes",width:"1421",height:"363"})}),"\n",(0,t.jsxs)(a.p,{children:["Above is an abyssinian cat. ResNet misidentified it as a snake \u2013 or perhaps a hat \u2013 before a cat. Layered over each prediction is a heatmap. Each region\xa0\u2013\xa0their number determined by ",(0,t.jsx)(a.code,{children:"eval_count"})," \u2013\xa0ranges from red (indicating that the area was instrumental in making the machine identify the image as that class) to blue (indicating that it made the machine less likely to pick that class)."]}),"\n",(0,t.jsx)(a.h3,{id:"required-concepts",children:"Required concepts"}),"\n",(0,t.jsx)(a.p,{children:"Cat/Dog\nTumor\nWhat did Shapley reveal about the tumors dataset\nWhat interesting results came up\nUser Study\nWhat kinds of feedback did we receive?"})]})}function p(e={}){const{wrapper:a}={...(0,n.M)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},5020:(e,a,s)=>{s.d(a,{c:()=>t});const t=s.p+"assets/images/abyssinian-3-cf1f6f3e187076f5f9c268d724f6e487.png"},2172:(e,a,s)=>{s.d(a,{I:()=>l,M:()=>r});var t=s(1504);const n={},i=t.createContext(n);function r(e){const a=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function l(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),t.createElement(i.Provider,{value:a},e.children)}}}]);