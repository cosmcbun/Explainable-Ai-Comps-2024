---
sidebar_position: 2
---


# Introducing Our Project


As a [2024 Comps/Capstone for Carleton College's Computer Science Department](https://cs.carleton.edu/cs_comps/2324/explainable-ai/index.php), this project has two parallel tracks following the literature review: appling [XAI](./What%20is%20XAI.md) techniques to [tabular categorization problems](../Methodology/MOOC.md) and appling XAI techniques to [image categorization problems](../Methodology/ResNet.md).






import ProjectOverview from './src/ProjectOverview.png';


<img src={ProjectOverview} alt="Project Overview Flowchart illustrating the similarity between the tabular and image track" style={{width: 400}} />


The same three XAI are applied to both tracks: [LIME](../LIME/Introduction.md), [Shapley](../Shapley%20Values/Introduction.md), and [Anchoring](../Anchors/Introduction.md).




By applying three XAI techniques to two different models, we are able to compare how the XAI techniques perform in different contexts. To further compare the XAI techniques, we are conducting two [user studies](../User%20Study/Introduction.md).


This project culminates in this website, [five posters](../Posters.md), and the [publishing of our code base](https://github.com/cosmcbun/Explainable-Ai-Comps-2024/).


==LEV: Do I need to add why each part of the project is important? ==




<!-- ## Deliverables




It is of primary importance that the group understands our three explainable AI methods. This necessitates a literature review, with papers and articles that introduce and implement Shapley and Anchor/LIME. After reading about them, we also want to implement them on complex existing models like ResNet. While the models will mostly be imported, this code base connecting existing models with existing XAI libraries will be another deliverable for our final project.


However, we don’t just want to understand these methods for our own oral exams’ sakes, but also so we can explain them to other students and get their feedback. We want to have a user study, headed by Josh, Tom, Chris and Sam, to lead this effort. With examples pulled from our data (like annotated images) that can be presented to peers for their feedback, we will ask about how compelling they find the explanation (versus the other XAI techniques), what could be improved, and whether it inspires confidence in them regarding the model as a whole. The product of this user study – whether in the form of notes, recordings, or filled-out surveys, would be another deliverable. While we shouldn’t need to recruit many students, depending on how many questions we want to ask, we will also need some resources to encourage participation. 10 participants at 45 minutes each and \$12.5/hour - \$100 in total - should be more than enough for this purpose.


After the user study, we will need two more deliverables: posters, for the poster session, and a website to show our results (and maybe even allow users to play with the models themselves, if we have time). The website push will be led by Lev and Adrian, at least until the other components of the project are completed. In a successful version of this project, we will be able to clearly explain the differences between these tools to anyone who comes to our poster sessions or website, along with data gathered from their peers about the qualitative efficacy of each technique.






## Our Vision


Through this project, we explore three major avenues for model explainability across two contrasting domains of machine-learning tasks (ResNet and MOOC). Namely, we will be apply Shapley, LIME, and Anchoring to two separate models of unique architecture which specialize in classification based on tabular and image data, respectively. On this site, you will find a comprehensive analysis of each method’s approach, what they highlight, and how they compare to the others. We discuss the literature surrounding these methods, and we compare their performances, including a user study. -->





