# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hy5KESFet5n9i2WibDoGjHN1kjkpp5Rn
"""

import shap
import json
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
import numpy as np
from torch.utils.data import random_split
import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
import torchvision.datasets as datasets
import PIL.Image as Image
import glob
import pickle
import matplotlib
import csv

device = torch.device("cuda")# if torch.cuda.is_available() else "cpu")

pretrained_weights = models.ResNet50_Weights.IMAGENET1K_V1
animal_model = models.resnet50(weights=pretrained_weights)
animal_model.eval()

#with open("animal_image_numpy.pickle", "rb") as f: animal_X = pickle.load(f)

def hashval(filepath):
  ending = filepath.split("/")[-1][:-4]
  animal, class_name, num = ending.split("-")
  num = int(num.split(" ")[0])
  total = (0 if animal == "dog" else 1)
  total = total*1000 + hash(class_name)%1000
  return total*1000 + num

animal_filelist = glob.glob("cat_dog_images/**/**/*")
animal_filelist.sort(key=hashval)
animal_X = {
  f"{filepath.split('-')[-2]}-{filepath.split('-')[-1][:-4]}":
  np.asarray(Image.open(filepath)) for filepath in animal_filelist
}
with open("animal_image_numpy.pickle", "wb") as f: pickle.dump(animal_X, f)

adversarial_filelist = animal_filelist = glob.glob("xai_img/**/*")
adversarial_X = {
  filepath[8:]:
  np.asarray(Image.open(filepath)) for filepath in adversarial_filelist
}

# getting ImageNet 1000 class names
url = "https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
with open(shap.datasets.cache(url)) as file:
    class_names = [v[1] for v in json.load(file).values()]

# python function to get model output; replace this function with your own model function.
def f(x):
    print(x.shape)
    tmp = x.copy()
    preprocess_input(tmp)
    answer = model(tmp)
    #print(type(answer), answer.shape)
    return answer

def filename_to_np(filepath):
    return np.asarray(Image.open(filepath))

def np_to_normalized_image(img):
    # Convert numpy array to PyTorch tensor and reorder dimensions if necessary
    img_tensor = torch.tensor(img).permute(0, 3, 1, 2).float()  # for a single image

    # Define normalization for 0-255 range images
    c=255
    mean = [0.485 * c, 0.456 * c, 0.406 * c]
    std = [0.229 * c, 0.224 * c, 0.225 * c]

    normalize = transforms.Normalize(mean=mean, std=std, inplace=True)

    # Apply normalization
    for img in img_tensor:
      normalize(img)

    # Add a batch dimension if processing a single image
    #img_normalized = img_normalized.unsqueeze(0)
    return img_tensor

def animal_torch_predict(x):
    if x.ndim == 4:
      return animal_model(np_to_normalized_image(x))
    #elif x.ndim == 3:
    #  return animal_model(np_to_normalized_image(x[np.newaxis]))

"""# Pass the normalized image to the model
output = animal_model(np_to_normalized_image(filename_to_np(animal_filelist[4998])[np.newaxis]))
predicted_class_index = torch.argmax(output, dim=1)
predicted_class = class_names[predicted_class_index].lower()
print(predicted_class)"""

"""mismatched_animals = []
with open("class_mismatches.csv") as file:
  spamreader = csv.reader(file)
  for row in spamreader:
    if row[4] == "2" or row[4] == "3":
      mismatched_animals.append(row[2].split("/")[-1][4:-4])"""

animals = ["abyssinian-3", "bengal-67", "german_shorthaired-79", "persian-57", "birman-16", "birman-171", "pug-192", "sphynx-151", "great_pyrenees-53", "abyssinian-71", "british_shorthair-78", "russian_blue-56"]
#animals = [f[8:] for f in adversarial_filelist]
#masker_blur = shap.maskers.Image("blur(128,128)", animal_X["american_bulldog-0"].shape)

for animal_name in animals:
  masker_blur = shap.maskers.Image("blur(128,128)", animal_X[animal_name].shape)
  print(masker_blur)
  print(type(masker_blur))
  explainer_blur = shap.Explainer(animal_torch_predict, masker_blur, output_names=class_names)
  # 35 s/iteration
  evals = 600#8000*60/6
  print("Animal:", animal_name)
  shap_values = explainer_blur(
      animal_X[animal_name][np.newaxis], max_evals=evals, batch_size=50, outputs=shap.Explanation.argsort.flip[:3]
  )
  plot = shap.image_plot(shap_values, show=True)
  matplotlib.pyplot.savefig(f"renders/{animal_name}")
  matplotlib.pyplot.close()


"""for animal_name in animals:
  masker_blur = shap.maskers.Image("blur(128,128)", adversarial_X[animal_name].shape)
  explainer_blur = shap.Explainer(animal_torch_predict, masker_blur, output_names=class_names)
  # 35 s/iteration
  evals = 6000#8000*60/6
  print("Animal:", animal_name)
  shap_values = explainer_blur(
      adversarial_X[animal_name][np.newaxis], max_evals=evals, batch_size=50, outputs=shap.Explanation.argsort.flip[:3]
  )
  plot = shap.image_plot(shap_values, show=False)
  #matplotlib.pyplot.savefig(f"renders/xai_img/{animal_name}")
  matplotlib.pyplot.close()"""

