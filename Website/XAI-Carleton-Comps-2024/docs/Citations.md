 Bibliography

_Artificial Intelligence Act: Deal on comprehensive rules for trustworthy AI | News | European Parliament_. (2023, December 9). [https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai)

Besse, P., Castets-Renard, C., Garivier, A., & Jean-Michel Loubes. (2018). Can everyday AI be ethical. Fairness of Machine Learning Algorithms. _arXiv.Org_. [https://doi.org/10.48550/arxiv.1810.01729](https://doi.org/10.48550/arxiv.1810.01729)

_Blueprint for an AI Bill of Rights | OSTP_. (n.d.). The White House. Retrieved March 4, 2024, from [https://www.whitehouse.gov/ostp/ai-bill-of-rights/](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)

Dhinakaran, A. (2021, September 21). _A Look Into Global, Cohort and Local Model Explainability_. Medium. [https://towardsdatascience.com/a-look-into-global-cohort-and-local-model-explainability-973bd449969f](https://towardsdatascience.com/a-look-into-global-cohort-and-local-model-explainability-973bd449969f)

Fernández, M. (n.d.). _AI in Banking: AI Will Be An Incremental Game Changer_. Retrieved March 4, 2024, from [https://www.spglobal.com/en/research-insights/featured/special-editorial/ai-in-banking-ai-will-be-an-incremental-game-changer](https://www.spglobal.com/en/research-insights/featured/special-editorial/ai-in-banking-ai-will-be-an-incremental-game-changer)

Muthukumar, V. (2019). _MOOCs-Dropout-Prediction_ (0c15fe3) \[Jupyter Notebook\]. [https://github.com/vickymhs/MOOCs-Dropout-Prediction](https://github.com/vickymhs/MOOCs-Dropout-Prediction)

Muthukumar, V., & Natarajan, B. (2020). MOOCVERSITY - Deep Learning Based Dropout Prediction in MOOCs over Weeks. _Journal of Soft Computing Paradigm_, _2_(3), 140–152. [https://doi.org/10.36548/jscp.2020.3.001](https://doi.org/10.36548/jscp.2020.3.001)

Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). “Why Should I Trust You?”: Explaining the Predictions of Any Classifier. _arXiv.Org_. [https://doi.org/10.48550/arxiv.1602.04938](https://doi.org/10.48550/arxiv.1602.04938)

Ribeiro, M. T., Singh, S., & Guestrin, C. (2018). Anchors: High-Precision Model-Agnostic Explanations. _AAAI Conference on Artificial Intelligence (AAAI)_.

Sim, J. Z. T., Fong, Q. W., Huang, W., & Tan, C. H. (2023). Machine learning in medicine: What clinicians should know. _Singapore Medical Journal_, _64_(2), 91. [https://doi.org/10.11622/smedj.2021054](https://doi.org/10.11622/smedj.2021054)

Štrumbelj, E., & Kononenko, I. (2014). Explaining prediction models and individual predictions with feature contributions. _Knowledge and Information Systems_, _41_(3), 647–665. [https://doi.org/10.1007/s10115-013-0679-x](https://doi.org/10.1007/s10115-013-0679-x)

Zieniūtė, U. (2023, November 19). _Is GitHub Copilot safe to use at work? | NordVPN_. [https://nordvpn.com/blog/is-github-copilot-safe-to-use-at-work/](https://nordvpn.com/blog/is-github-copilot-safe-to-use-at-work/)
