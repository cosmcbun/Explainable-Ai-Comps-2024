"use strict";(self.webpackChunkxai_carleton_comps_2024=self.webpackChunkxai_carleton_comps_2024||[]).push([[1792],{7056:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>d});var i=n(7624),s=n(2172);const o={},a="MOOC Dropout Prediction",r={id:"Methodology/MOOC",title:"MOOC Dropout Prediction",description:"The MOOC Dataset",source:"@site/docs/Methodology/MOOC.md",sourceDirName:"Methodology",slug:"/Methodology/MOOC",permalink:"/Explainable-Ai-Comps-2024/Methodology/MOOC",draft:!1,unlisted:!1,editUrl:"https://github.com/cosmcbun/Explainable-Ai-Comps-2024/tree/main/Website/XAI-Carleton-Comps-2024/docs/Methodology/MOOC.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Methodology",permalink:"/Explainable-Ai-Comps-2024/category/methodology"},next:{title:"ResNet Animal Classification",permalink:"/Explainable-Ai-Comps-2024/Methodology/ResNet"}},l={},d=[{value:"The MOOC Dataset",id:"the-mooc-dataset",level:2},{value:"Our Models",id:"our-models",level:2},{value:"Why explain these AIs?",id:"why-explain-these-ais",level:2},{value:"What features does our MOOC dataset provide?",id:"what-features-does-our-mooc-dataset-provide",level:2}];function c(e){const t={code:"code",em:"em",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.M)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{id:"mooc-dropout-prediction",children:"MOOC Dropout Prediction"}),"\n",(0,i.jsx)(t.h2,{id:"the-mooc-dataset",children:"The MOOC Dataset"}),"\n",(0,i.jsx)(t.p,{children:"This project\u2019s second model involves machine learning models trained to predict student dropout based on interaction data in MOOCs (Massive Open Online Courses). This is an interesting problem, as their low cost and easily accessible nature compared to traditional college education has caused a drastic rise in interest in MOOCs recently. Despite their popularity, however, dropout rates remain extremely high, often exceeding 90%. As such, teachers of MOOCs must devote significant amounts of time just to figuring out resource allocation - when there are more than 60 thousand students in your course, how can you decide who needs help?"}),"\n",(0,i.jsx)(t.p,{children:"One pertinent answer may be machine learning."}),"\n",(0,i.jsx)(t.h2,{id:"our-models",children:"Our Models"}),"\n",(0,i.jsx)(t.p,{children:"While a human brain may take seconds to minutes pouring over every aspect of a student in order to predict their success or failure in a course, for a machine learning model this task is trivialized to single-digit milliseconds. As such, the MOOC dropout dataset has been a popular breeding ground for model/architecture testing. While there have been numerous models constructed to make these predictions, we have chosen to use a multi-layer perceptron (a neural network architecture) and a support-vector machine, as demonstrated by Vignesh Muthukumar (Muthukumar, 2019). Initialization of each is fairly simple, as shown below:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"# Support-Vector Machine:\nfrom sklearn import svm\nclf = svm.SVC(C=0.5, gamma='scale', probability=True)\n\n# Multi-Layer Perceptron:\nfrom sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(3, 15, 10), max_iter=1000)\n\n''' Alternate initialization for the MLPClassifier: '''\nimport keras\nmodel = keras.models.Sequential([\n            keras.layers.Dense(3, input_dim=10, activation='relu'),\n            keras.layers.Dense(15, activation='relu'),\n            keras.layers.Dense(10, activation='relu'),\n            keras.layers.Dense(2, activation='softmax')\n        ])\n"})}),"\n",(0,i.jsx)(t.p,{children:"Both of these networks achieve good results, but they can be messy, and skews in the data can make predictions unbalanced. As such, these models make for perfect candidates to explain."}),"\n",(0,i.jsx)(t.h2,{id:"why-explain-these-ais",children:"Why explain these AIs?"}),"\n",(0,i.jsx)(t.p,{children:"These models are strong candidates for explainability for several reasons. First, given the notorious \u201cblack box\u201d nature of neural networks and high-dimension SVMs, there are few options (apart from explainability methods) that offer easy insight into why the model may classify certain students as likely or unlikely to drop out of the MOOC. Additionally, there can be potentially significant ramifications for these students if they are predicted as likely to drop out, or not \u2013 a student flagged as likely to drop out may lose motivation, and the prediction may become a self fulfilling prophecy in cases where the student would have otherwise stayed in the course. On the other hand, a student who is truly at risk of dropping out but not identified as such may fail to be noticed by the instructional staff, due to the large and relatively autonomous nature of MOOCs. These significant stakes call for added scrutiny and insight into models making these predictions. Finally, explainability methods applied to MOOC dropout prediction can offer insight into what features successful and unsuccessful students exhibit."}),"\n",(0,i.jsx)(t.h2,{id:"what-features-does-our-mooc-dataset-provide",children:"What features does our MOOC dataset provide?"}),"\n",(0,i.jsx)(t.p,{children:"We used the following ten features in our predictions. Below you will find a short description of each, along with their average values:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"viewed"}),": whether the student has ever opened the course (",(0,i.jsx)(t.em,{children:"Average"}),": 0.61)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"gender"}),": female = 0, male = 1 (no third option given) (",(0,i.jsx)(t.em,{children:"Average"}),": 0.9)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"grade"}),": student\u2019s grade at the time of gathering (",(0,i.jsx)(t.em,{children:"Average"}),": 3.4%)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"nevents"}),": how much they interacted with the course (",(0,i.jsx)(t.em,{children:"Average"}),": 535)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"ndays_active"}),": how many days they logged in (",(0,i.jsx)(t.em,{children:"Average"}),": 6)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"nplay_video"}),": how many times they watched a video (",(0,i.jsx)(t.em,{children:"Average"}),": 58)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"nchapters"}),": how lessons they completed (",(0,i.jsx)(t.em,{children:"Average"}),": 2)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"age"}),": age of student (",(0,i.jsx)(t.em,{children:"Average"}),": 26)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"votes"}),": how many times they voted on the course forum (",(0,i.jsx)(t.em,{children:"Average"}),": 0.67)"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"num_words"}),": how many total words they wrote in the course forum (",(0,i.jsx)(t.em,{children:"Average"}),": 79)"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,s.M)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},2172:(e,t,n)=>{n.d(t,{I:()=>r,M:()=>a});var i=n(1504);const s={},o=i.createContext(s);function a(e){const t=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);